/*
Copyright IBM Corporation 2020

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

	http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package filesystem

import (
	"bufio"
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net"
	"net/http"
	"os"
	"os/exec"
	"path/filepath"
	"regexp"
	"sort"
	"strings"
	"sync"
	"syscall"
	"time"

	"github.com/go-resty/resty/v2"
	"github.com/konveyor/move2kube-api/cmd/version"
	"github.com/konveyor/move2kube-api/internal/common"
	"github.com/konveyor/move2kube-api/internal/types"
	"github.com/mholt/archiver/v3"
	"github.com/phayes/freeport"
	"github.com/sirupsen/logrus"
	"github.com/spf13/cast"
	bolt "go.etcd.io/bbolt"
	"gopkg.in/yaml.v3"
)

const (
	// WORKSPACES_DIR is the name of the directory where the workspaces are stored
	WORKSPACES_DIR = "workspaces"
	// PROJECTS_DIR is the name of the directory where the projects are stored
	PROJECTS_DIR = "projects"
	// INPUTS_DIR is the directory where project inputs are stored
	INPUTS_DIR = "inputs"
	// PROJECT_OUTPUTS_DIR is the directory where project outputs are stored
	PROJECT_OUTPUTS_DIR = "outputs"
	// PROJECT_PLAN_DIR is the directory where planning is done
	PROJECT_PLAN_DIR = "plan"
	// ARCHIVES_DIR is the directory where the archive files for project inputs are stored
	ARCHIVES_DIR = "archives"
	// EXPANDED_DIR is the directory where the archive files for project inputs are expanded and stored
	EXPANDED_DIR = "expanded"
	// SOURCES_DIR is the directory where the sources directory project inputs are stored
	SOURCES_DIR = string(types.ProjectInputSources)
	// CUSTOMIZATIONS_DIR is the directory where the customizations directory project inputs are stored
	CUSTOMIZATIONS_DIR = string(types.ProjectInputCustomizations)
	// CONFIGS_DIR is the directory where the configs files project inputs are stored
	CONFIGS_DIR = string(types.ProjectInputConfigs)
	// M2K_PLAN_FILENAME is the name of the plan file generated by Move2Kube CLI
	M2K_PLAN_FILENAME = common.APP_NAME_SHORT + ".plan"
	// M2K_QA_SERVER_METADATA_FILE is the name of the file containing the QA server metadata
	M2K_QA_SERVER_METADATA_FILE = common.APP_NAME_SHORT + ".qaserver"
	// M2K_PLAN_PROGRESS_SERVER_METADATA_FILE is the name of the file containing the plan progress server metadata
	M2K_PLAN_PROGRESS_SERVER_METADATA_FILE = common.APP_NAME_SHORT + ".planprogressserver"
	// M2K_CLI_LOG_FILE is the name of the log file that the CLI writes to
	M2K_CLI_LOG_FILE = common.APP_NAME_SHORT + "cli.log"
	// PROJECT_METADATA_FILE is the name of the file containing the project metadata
	PROJECT_METADATA_FILE = "metadata"
	// DEFAULT_DIRECTORY_PERMISSIONS is the default permissions used when creating new directories
	DEFAULT_DIRECTORY_PERMISSIONS os.FileMode = 0775
	// DEFAULT_FILE_PERMISSIONS is the default permissions used when creating new files
	DEFAULT_FILE_PERMISSIONS os.FileMode = 0660
	// DATABASE_FILENAME is the database filename
	DATABASE_FILENAME = "database"
	// WORKSPACES_BUCKET is the workspaces bucket
	WORKSPACES_BUCKET = "workspaces"
	// PROJECTS_BUCKET is the projects bucket
	PROJECTS_BUCKET = "projects"
)

var (
	// VALID_ARCHIVE_EXTS is the list of archive formats that are supported
	VALID_ARCHIVE_EXTS = []string{".zip", ".tar", ".tgz", ".gz"}
	// LOG_LEVEL_REGEXP is the regexp used to capture the loglevel from the CLI output
	LOG_LEVEL_REGEXP = regexp.MustCompile(`level=([a-z]+) `)
	// TIMESTAMP_REGEXP is the regexp used to replace the the timestamp in the CLI output with a different message
	TIMESTAMP_REGEXP = regexp.MustCompile(`time="\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}(Z|\+\d{2}:\d{2})"`)
)

/*
Workspace Folder Structure
--------------------------
We make a copy of the entire source and config folders whenever a new run is triggered (by clicking the Transform button)
to avoid race conditions with some user changing the source folder while a plan or transformation is in progress.

It also allows for resuming previous runs. We remove the output folder if it exists (while preserving the m2kqaconfig file).
NOTE: don't need to preserve the m2kqacache because we cannot provide it to the subsequent runs to resume. The qacache flag has been removed from the CLI.

This also allows for neat features like showing a diff of the folder structure between runs.
This architecture should support multiple pod restarts (even during planning/translation).

TODO: also need to figure out where to put the config files. Currently we are not accepting upload or use of config files.

Database structure:
There are 4 buckets. Each bucket is a key value store.

workspaces bucket    [workspace_id]      -> workspace
projects bucket      [project_id]        -> project
plan_progress_bucket [project_id]        -> plan progress server metadata
qa_server_bucket     [project_output_id] -> qa server metadata

Filesystem structure:
data/
	workspaces/
		work-id-1/
			inputs/
				archives/
					sources/
						lang-plat.zip
						estore.tar.gz
					customizations/
						cust-1.zip
						cust-2.zip
				expanded/
					sources/
						lang-plat/
						estore/
						.m2kignore
					customizations/
						cust-1/
						cust-2/
					configs/
						config-1.yaml
						config-2.yaml
					m2k.plan
					m2kcli.log
	projects/
		project-id-1/
			inputs/
				archives/
					sources/
						lang-plat.zip
						estore.tar.gz
					customizations/
						cust-1.zip
						cust-2.zip
				expanded/
					sources/
						lang-plat/
						estore/
						.m2kignore
					customizations/
						cust-1/
						cust-2/
					configs/
						config-1.yaml
						config-2.yaml
					m2k.plan
					m2kcli.log
			outputs/
				run-id-1/
					sources/
						lang-plat/
						estore/
						.m2kignore
					customizations/
						cust-1/
						cust-2/
					configs/
						config-1.yaml
						config-2.yaml
					m2k.plan
					m2kconfig.yaml
					m2kqacache.yaml
					m2kcli.log
					output/
					output.zip
				run-id-2/
*/

// FileSystem implements the IFileSystem interface and manages the workspace and project data in the filesystem
type FileSystem struct{}

// GetDatabase returns the database. The database must be closed by the caller.
func (*FileSystem) GetDatabase(readOnly bool) (*bolt.DB, error) {
	databasePath := filepath.Join(common.Config.DataDir, DATABASE_FILENAME)
	db, err := bolt.Open(databasePath, DEFAULT_FILE_PERMISSIONS, &bolt.Options{ReadOnly: readOnly})
	if err != nil {
		return db, fmt.Errorf("failed to open the database at path %s . Error: %q", databasePath, err)
	}
	return db, nil
}

// GetSupportInfo returns information useful for debugging.
// Returns the output of move2kube version -l
func (*FileSystem) GetSupportInfo() map[string]string {
	cmd := exec.Command("move2kube", "version", "-l")
	cliVersionBytes, err := cmd.Output()
	if err != nil {
		logrus.Errorf("Failed to get the move2kube CLI version information. Error: %q", err)
		return nil
	}
	info := map[string]string{}
	info["cli_version"] = string(cliVersionBytes)
	info["api_version"] = version.GetVersion(true)
	uiVersion := struct {
		Version      string `yaml:"version"`
		GitCommit    string `yaml:"gitCommit"`
		GitTreeState string `yaml:"gitTreeState"`
	}{}
	found := false
	if val, ok := os.LookupEnv("MOVE2KUBE_UI_VERSION"); ok {
		uiVersion.Version = val
		found = true
	}
	if val, ok := os.LookupEnv("MOVE2KUBE_UI_GIT_COMMIT_HASH"); ok {
		uiVersion.GitCommit = val
		found = true
	}
	if val, ok := os.LookupEnv("MOVE2KUBE_UI_GIT_TREE_STATUS"); ok {
		uiVersion.GitTreeState = val
		found = true
	}
	info["ui_version"] = "unknown"
	if found {
		if uiVersionBytes, err := yaml.Marshal(uiVersion); err != nil {
			logrus.Errorf("failed to marshal the support info for the UI %+v to yaml. Error: %q", uiVersion, err)
		} else {
			info["ui_version"] = string(uiVersionBytes)
		}
	}
	info["docker"] = "docker socket is mounted"
	if _, err := os.Stat("/var/run/docker.sock"); err != nil {
		if os.IsNotExist(err) {
			info["docker"] = "docker socket is not mounted"
		} else {
			info["docker"] = fmt.Sprintf("docker socket error: %q", err)
		}
	}
	return info
}

// Download returns the app binary
func (*FileSystem) Download() (io.Reader, string, error) {
	path, err := exec.LookPath(common.APP_NAME)
	if err != nil {
		return nil, "", fmt.Errorf("unable to find the app executable named '%s' . Error: %q", common.APP_NAME, err)
	}
	f, err := os.Open(path)
	if err != nil {
		return nil, "", fmt.Errorf("failed to open the file at path %s . Error: %q", path, err)
	}
	return f, filepath.Base(path), nil
}

// ListWorkspaceIds returns the list of workspace Ids
func (fs *FileSystem) ListWorkspaceIds() ([]string, error) {
	db, err := fs.GetDatabase(true)
	if err != nil {
		return nil, err
	}
	defer db.Close()
	wids := []string{}
	err = db.View(func(t *bolt.Tx) error {
		wids, err = fs.listWorkspaceIds(t)
		return err
	})
	return wids, err
}

func (*FileSystem) listWorkspaceIds(t *bolt.Tx) ([]string, error) {
	workspaceIds := []string{}
	workBucket := t.Bucket([]byte(WORKSPACES_BUCKET))
	if workBucket == nil {
		return workspaceIds, fmt.Errorf("failed to get the workspaces bucket '%s'", WORKSPACES_BUCKET)
	}
	err := workBucket.ForEach(func(workspaceId, _ []byte) error {
		workspaceIds = append(workspaceIds, string(workspaceId))
		return nil
	})
	return workspaceIds, err
}

// ListWorkspaces returns the list of workspaces
func (fs *FileSystem) ListWorkspaces(workspaceIds []string) ([]types.Workspace, error) {
	db, err := fs.GetDatabase(true)
	if err != nil {
		return nil, err
	}
	defer db.Close()
	ws := []types.Workspace{}
	err = db.View(func(t *bolt.Tx) error {
		ws, err = fs.listWorkspaces(t, workspaceIds)
		return err
	})
	return ws, err
}

func (*FileSystem) listWorkspaces(t *bolt.Tx, workspaceIds []string) ([]types.Workspace, error) {
	workspaces := []types.Workspace{}
	workBucket := t.Bucket([]byte(WORKSPACES_BUCKET))
	if workBucket == nil {
		return workspaces, fmt.Errorf("failed to get the workspaces bucket '%s'", WORKSPACES_BUCKET)
	}
	err := workBucket.ForEach(func(workspaceId, workBytes []byte) error {
		if workspaceIds != nil && !common.IsStringPresent(workspaceIds, string(workspaceId)) {
			return nil
		}
		work := types.Workspace{}
		if err := json.Unmarshal(workBytes, &work); err != nil {
			logrus.Errorf("failed to unmarshal the workspace %s as json. Actual: %s\nError: %q", string(workspaceId), string(workBytes), err)
			return nil
		}
		workspaces = append(workspaces, work)
		return nil
	})
	return workspaces, err
}

// CreateWorkspace creates a new workspace
func (fs *FileSystem) CreateWorkspace(workspace types.Workspace) error {
	db, err := fs.GetDatabase(false)
	if err != nil {
		return err
	}
	defer db.Close()
	return db.Update(func(t *bolt.Tx) error {
		return fs.createWorkspace(t, workspace)
	})
}

func (*FileSystem) createWorkspace(t *bolt.Tx, workspace types.Workspace) error {
	workBucket := t.Bucket([]byte(WORKSPACES_BUCKET))
	if workBucket == nil {
		return fmt.Errorf("workspace bucket is missing")
	}
	if v := workBucket.Get([]byte(workspace.Id)); v != nil {
		return types.ErrorIdAlreadyInUse{Id: workspace.Id}
	}
	workBytes, err := json.Marshal(workspace)
	if err != nil {
		return fmt.Errorf("failed to marshal the workspace as json. Error: %q", err)
	}
	if err := workBucket.Put([]byte(workspace.Id), workBytes); err != nil {
		return fmt.Errorf("failed to set the workspace id '%s' to the workspace %s in the workspaces bucket. Error: %q", workspace.Id, string(workBytes), err)
	}
	return nil
}

// ReadWorkspace reads an existing workspace
func (fs *FileSystem) ReadWorkspace(workspaceId string) (types.Workspace, error) {
	db, err := fs.GetDatabase(true)
	if err != nil {
		return types.Workspace{}, err
	}
	defer db.Close()
	work := types.Workspace{}
	err = db.View(func(t *bolt.Tx) error {
		work, err = fs.readWorkspace(t, workspaceId)
		return err
	})
	return work, err
}

func (*FileSystem) readWorkspace(t *bolt.Tx, workspaceId string) (types.Workspace, error) {
	work := types.Workspace{}
	workBucket := t.Bucket([]byte(WORKSPACES_BUCKET))
	if workBucket == nil {
		return work, types.ErrorDoesNotExist{Id: workspaceId}
	}
	workBytes := workBucket.Get([]byte(workspaceId))
	if workBytes == nil {
		return work, types.ErrorDoesNotExist{Id: workspaceId}
	}
	if err := json.Unmarshal(workBytes, &work); err != nil {
		return work, fmt.Errorf("failed to unmarshal the workspace as json. Actual: %s\nError: %q", string(workBytes), err)
	}
	if work.Inputs == nil {
		work.Inputs = map[string]types.ProjectInput{}
	}
	return work, nil
}

// UpdateWorkspace updates an existing workspace
func (fs *FileSystem) UpdateWorkspace(workspace types.Workspace) error {
	db, err := fs.GetDatabase(false)
	if err != nil {
		return err
	}
	defer db.Close()
	return db.Update(func(t *bolt.Tx) error {
		return fs.updateWorkspace(t, workspace)
	})
}

func (*FileSystem) updateWorkspace(t *bolt.Tx, workspace types.Workspace) error {
	workBucket := t.Bucket([]byte(WORKSPACES_BUCKET))
	if workBucket == nil {
		return fmt.Errorf("workspace bucket is missing")
	}
	if v := workBucket.Get([]byte(workspace.Id)); v == nil {
		return types.ErrorDoesNotExist{Id: workspace.Id}
	}
	workBytes, err := json.Marshal(workspace)
	if err != nil {
		return fmt.Errorf("failed to marshal the workspace as json. Error: %q", err)
	}
	if err := workBucket.Put([]byte(workspace.Id), workBytes); err != nil {
		return fmt.Errorf("failed to set the workspace id '%s' to the workspace %s in the workspaces bucket. Error: %q", workspace.Id, string(workBytes), err)
	}
	return nil
}

// DeleteWorkspace deletes an existing workspace
func (fs *FileSystem) DeleteWorkspace(workspaceId string) error {
	db, err := fs.GetDatabase(false)
	if err != nil {
		return err
	}
	defer db.Close()
	return db.Update(func(t *bolt.Tx) error {
		return fs.deleteWorkspace(t, workspaceId)
	})
}

func (fs *FileSystem) deleteWorkspace(t *bolt.Tx, workspaceId string) error {
	work, err := fs.readWorkspace(t, workspaceId)
	if err != nil {
		return err
	}
	for _, projectId := range work.ProjectIds {
		if err := fs.deleteProject(t, workspaceId, projectId); err != nil {
			logrus.Errorf("failed to delete the project %s in the workspace %s . Error: %q", projectId, workspaceId, err)
			return err
		}
	}
	for _, workInp := range work.Inputs {
		if err := fs.deleteWorkspaceInput(t, workspaceId, workInp); err != nil {
			logrus.Errorf("failed to delete the workspace level input %s in the workspace %s . Error: %q", workInp.Id, workspaceId, err)
			return err
		}
	}
	workBucket := t.Bucket([]byte(WORKSPACES_BUCKET))
	if workBucket == nil {
		return fmt.Errorf("workspaces bucket is missing")
	}
	if err := workBucket.Delete([]byte(workspaceId)); err != nil {
		return fmt.Errorf("failed to delete the workspace with id '%s' in the workspaces bucket. Error: %q", workspaceId, err)
	}
	return nil
}

// ListProjects returns the list of projects in the workspace
func (fs *FileSystem) ListProjects(workspaceId string) ([]types.Project, error) {
	db, err := fs.GetDatabase(true)
	if err != nil {
		return nil, err
	}
	defer db.Close()
	projs := []types.Project{}
	err = db.View(func(t *bolt.Tx) error {
		projs, err = fs.listProjects(t, workspaceId)
		return err
	})
	return projs, err
}

func (fs *FileSystem) listProjects(t *bolt.Tx, workspaceId string) ([]types.Project, error) {
	work, err := fs.readWorkspace(t, workspaceId)
	if err != nil {
		return nil, err
	}
	projects := []types.Project{}
	for _, projectId := range work.ProjectIds {
		project, err := fs.readProject(t, workspaceId, projectId)
		if err != nil {
			logrus.Errorf("failed to read the project with id: %s . Error: %q", projectId, err)
			continue
		}
		projects = append(projects, project)
	}
	return projects, nil
}

// CreateProject creates a new project in the filesystem
func (fs *FileSystem) CreateProject(workspaceId string, project types.Project) error {
	db, err := fs.GetDatabase(false)
	if err != nil {
		return err
	}
	defer db.Close()
	return db.Update(func(t *bolt.Tx) error {
		return fs.createProject(t, workspaceId, project)
	})
}

func (fs *FileSystem) createProject(t *bolt.Tx, workspaceId string, project types.Project) error {
	// check conditions
	work, err := fs.readWorkspace(t, workspaceId)
	if err != nil {
		return err
	}
	if common.IsStringPresent(work.ProjectIds, project.Id) {
		return types.ErrorIdAlreadyInUse{Id: project.Id}
	}
	projBucket := t.Bucket([]byte(PROJECTS_BUCKET))
	if projBucket == nil {
		return fmt.Errorf("the projects bucket is missing")
	}
	// update state
	projBytes, err := json.Marshal(project)
	if err != nil {
		return fmt.Errorf("failed to marshal project %+v as json. Error: %q", project, err)
	}
	if err := projBucket.Put([]byte(project.Id), projBytes); err != nil {
		return fmt.Errorf("failed to put the project %s in the projects bucket. Actual: %s\nError: %q", project.Id, string(projBytes), err)
	}
	work.ProjectIds = append(work.ProjectIds, project.Id)
	if err := fs.updateWorkspace(t, work); err != nil {
		return fmt.Errorf("failed to update the workspace with id: %s . Error: %q", workspaceId, err)
	}
	// effects
	logrus.Debugf("creating a new project: %+v in the workspace with id: %s", project, workspaceId)
	projDir := filepath.Join(common.Config.DataDir, PROJECTS_DIR, project.Id)
	if err := os.MkdirAll(projDir, DEFAULT_DIRECTORY_PERMISSIONS); err != nil {
		return fmt.Errorf("failed to make the project directory at path %s . Error: %q", projDir, err)
	}
	return nil
}

// ReadProject returns the metadata about a project
func (fs *FileSystem) ReadProject(workspaceId string, projectId string) (types.Project, error) {
	project := types.Project{}
	db, err := fs.GetDatabase(true)
	if err != nil {
		return project, err
	}
	defer db.Close()
	proj := types.Project{}
	err = db.View(func(t *bolt.Tx) error {
		proj, err = fs.readProject(t, workspaceId, projectId)
		return err
	})
	return proj, err
}

func (fs *FileSystem) readProject(t *bolt.Tx, workspaceId string, projectId string) (types.Project, error) {
	project := types.Project{}
	if _, err := fs.readWorkspace(t, workspaceId); err != nil {
		return project, err
	}
	projBucket := t.Bucket([]byte(PROJECTS_BUCKET))
	if projBucket == nil {
		return project, fmt.Errorf("the projects bucket is missing")
	}
	projectBytes := projBucket.Get([]byte(projectId))
	if projectBytes == nil {
		return project, types.ErrorDoesNotExist{Id: projectId}
	}
	if err := json.Unmarshal(projectBytes, &project); err != nil {
		return project, fmt.Errorf("failed to unmarshal the project as json. Error: %q\nActual: %s", err, string(projectBytes))
	}
	if project.Inputs == nil {
		project.Inputs = map[string]types.ProjectInput{}
	}
	if project.Outputs == nil {
		project.Outputs = map[string]types.ProjectOutput{}
	}
	if project.Status == nil {
		project.Status = map[types.ProjectStatus]bool{}
	}
	logrus.Debugf("readProject project: %+v", project)
	return project, nil
}

// UpdateProject updates a new project in the filesystem
func (fs *FileSystem) UpdateProject(workspaceId string, project types.Project) error {
	db, err := fs.GetDatabase(false)
	if err != nil {
		return err
	}
	defer db.Close()
	return db.Update(func(t *bolt.Tx) error {
		return fs.updateProject(t, workspaceId, project)
	})
}

func (fs *FileSystem) updateProject(t *bolt.Tx, workspaceId string, project types.Project) error {
	// check conditions
	work, err := fs.readWorkspace(t, workspaceId)
	if err != nil {
		return err
	}
	if !common.IsStringPresent(work.ProjectIds, project.Id) {
		return types.ErrorDoesNotExist{Id: project.Id}
	}
	projBucket := t.Bucket([]byte(PROJECTS_BUCKET))
	if projBucket == nil {
		return fmt.Errorf("the projects bucket is missing")
	}
	// update state
	projBytes, err := json.Marshal(project)
	if err != nil {
		return fmt.Errorf("failed to marshal project %+v as json. Error: %q", project, err)
	}
	if err := projBucket.Put([]byte(project.Id), projBytes); err != nil {
		return fmt.Errorf("failed to update the project %+v in the projects bucket. Error: %q", project, err)
	}
	return nil
}

// DeleteProject deletes an project from the filesysem
func (fs *FileSystem) DeleteProject(workspaceId string, projectId string) error {
	db, err := fs.GetDatabase(false)
	if err != nil {
		return err
	}
	defer db.Close()
	return db.Update(func(t *bolt.Tx) error {
		// check conditions
		work, err := fs.readWorkspace(t, workspaceId)
		if err != nil {
			return err
		}
		if !common.IsStringPresent(work.ProjectIds, projectId) {
			return types.ErrorDoesNotExist{Id: projectId}
		}
		// update state
		filtered := []string{}
		for _, pid := range work.ProjectIds {
			if pid == projectId {
				continue
			}
			filtered = append(filtered, pid)
		}
		work.ProjectIds = filtered
		if err := fs.updateWorkspace(t, work); err != nil {
			return fmt.Errorf("failed to update the workspace with id: %s . Error: %q", workspaceId, err)
		}
		return fs.deleteProject(t, workspaceId, projectId)
	})
}

func (fs *FileSystem) deleteProject(t *bolt.Tx, workspaceId string, projectId string) error {
	project, err := fs.readProject(t, workspaceId, projectId)
	if err != nil {
		return fmt.Errorf("failed to read the project %s . Error: %q", projectId, err)
	}
	// cannot delete while planning
	if project.Status[types.ProjectStatusPlanning] {
		return types.ErrorOngoing{Id: projectId}
	}
	// cannot delete while transforming
	for _, projOutput := range project.Outputs {
		if projOutput.Status == types.ProjectOutputStatusInProgress {
			return types.ErrorOngoing{Id: projOutput.Id}
		}
	}
	projBucket := t.Bucket([]byte(PROJECTS_BUCKET))
	if projBucket == nil {
		return fmt.Errorf("the projects bucket is missing")
	}
	if err := projBucket.Delete([]byte(projectId)); err != nil {
		return fmt.Errorf("failed to delete the project %s from the projects bucket '%s' . Error: %q", projectId, PROJECTS_BUCKET, err)
	}
	planBucket := t.Bucket([]byte(M2K_PLAN_PROGRESS_SERVER_METADATA_FILE))
	if planBucket == nil {
		return fmt.Errorf("the plan progress server bucket is missing")
	}
	if err := planBucket.Delete([]byte(projectId)); err != nil {
		return fmt.Errorf("failed to delete the project %s from the plan progress server bucket '%s' . Error: %q", projectId, M2K_PLAN_PROGRESS_SERVER_METADATA_FILE, err)
	}
	qaBucket := t.Bucket([]byte(M2K_QA_SERVER_METADATA_FILE))
	if qaBucket == nil {
		return fmt.Errorf("the qa server bucket is missing")
	}
	for projOutputId := range project.Outputs {
		if err := qaBucket.Delete([]byte(projOutputId)); err != nil {
			return fmt.Errorf("failed to delete the output %s of the project %s from the qa server bucket '%s' . Error: %q", projOutputId, projectId, M2K_QA_SERVER_METADATA_FILE, err)
		}
	}
	// effects
	projDir := filepath.Join(common.Config.DataDir, PROJECTS_DIR, projectId)
	if err := os.RemoveAll(projDir); err != nil {
		return fmt.Errorf("failed to remove the project at path %s . Error: %q", projDir, err)
	}
	return nil
}

// CreateProjectInput creates an input for the project in the filesystem
func (fs *FileSystem) CreateProjectInput(workspaceId, projectId string, projInput types.ProjectInput, file io.Reader, isCommon bool) error {
	db, err := fs.GetDatabase(false)
	if err != nil {
		return err
	}
	defer db.Close()
	return db.Update(func(t *bolt.Tx) error {
		if isCommon {
			return fs.createWorkspaceInput(t, workspaceId, projInput, file)
		}
		return fs.createProjectInput(t, workspaceId, projectId, projInput, file)
	})
}

func (fs *FileSystem) createWorkspaceInput(t *bolt.Tx, workspaceId string, workInput types.ProjectInput, file io.Reader) error {
	// check conditions
	work, err := fs.readWorkspace(t, workspaceId)
	if err != nil {
		return err
	}
	if _, ok := work.Inputs[workInput.Id]; ok {
		return types.ErrorIdAlreadyInUse{Id: workInput.Id}
	}
	for _, pi := range work.Inputs {
		if pi.NormalizedName == workInput.NormalizedName {
			reason := fmt.Sprintf("You have already uploaded an input with the filename '%s'. Please pick a different one.", workInput.NormalizedName)
			logrus.Debugf(reason)
			return types.ErrorValidation{Reason: reason}
		}
	}
	projs, err := fs.listProjects(t, workspaceId)
	if err != nil {
		for _, proj := range projs {
			for _, pi := range proj.Inputs {
				if pi.Type == types.ProjectInputReference {
					continue
				}
				if pi.NormalizedName == workInput.NormalizedName {
					reason := fmt.Sprintf("There is already an input with the filename '%s' for the project '%s'. Please pick a different one.", workInput.NormalizedName, proj.Id)
					logrus.Debugf(reason)
					return types.ErrorValidation{Reason: reason}
				}
			}
		}
	}
	// update state
	work.Inputs[workInput.Id] = workInput
	lastDir := ""
	if workInput.Type == types.ProjectInputSources {
		lastDir = SOURCES_DIR
	} else if workInput.Type == types.ProjectInputCustomizations {
		lastDir = CUSTOMIZATIONS_DIR
	} else if workInput.Type == types.ProjectInputConfigs {
		lastDir = CONFIGS_DIR
	} else if workInput.Type == types.ProjectInputReference {
		return types.ErrorValidation{Reason: "reference input type is not valid for workspaces"}
	} else {
		return types.ErrorValidation{Reason: fmt.Sprintf("invalid workspace input type: %s", workInput.Type)}
	}
	if err := fs.updateWorkspace(t, work); err != nil {
		return fmt.Errorf("failed to update the workspace with id: %s . Error: %q", workspaceId, err)
	}
	// effects
	logrus.Debugf("creating a new input for the workspace %s with type %s and filename %s", workspaceId, workInput.Type, workInput.Name)
	workInputsDir := filepath.Join(common.Config.DataDir, WORKSPACES_DIR, workspaceId, INPUTS_DIR)
	archDir := filepath.Join(workInputsDir, ARCHIVES_DIR, lastDir)
	archExpDir := filepath.Join(workInputsDir, EXPANDED_DIR, lastDir)
	archivePath := filepath.Join(archDir, workInput.NormalizedName)
	archiveExpandedPath := filepath.Join(archExpDir, workInput.NormalizedName)
	if err := os.RemoveAll(archivePath); err != nil {
		return fmt.Errorf("failed to remove the archive at path %s . Error: %q", archivePath, err)
	}
	if err := os.RemoveAll(archiveExpandedPath); err != nil {
		return fmt.Errorf("failed to remove the archive expanded directory at the path %s . Error: %q", archiveExpandedPath, err)
	}
	if workInput.Type == types.ProjectInputConfigs {
		// configs
		if err := os.MkdirAll(archExpDir, DEFAULT_DIRECTORY_PERMISSIONS); err != nil {
			return fmt.Errorf("failed to create a directory at the path %s . Error: %q", archExpDir, err)
		}
		// write the config file they uploaded
		f, err := os.OpenFile(archiveExpandedPath, os.O_WRONLY|os.O_CREATE, DEFAULT_FILE_PERMISSIONS)
		if err != nil {
			return fmt.Errorf("failed to write the config file to the path %s . Error: %q", archivePath, err)
		}
		defer f.Close()
		if _, err := io.Copy(f, file); err != nil {
			return fmt.Errorf("failed to receive and write the config file to the path %s completely. Error: %q", archiveExpandedPath, err)
		}
		return nil
	}
	// sources and customizations
	if err := os.MkdirAll(archDir, DEFAULT_DIRECTORY_PERMISSIONS); err != nil {
		return fmt.Errorf("failed to create the archive directory at the path %s . Error: %q", archDir, err)
	}
	if err := putM2KIgnore(archExpDir); err != nil { // also creates the directory if it doesn't exist, overwrites if it does exist
		return fmt.Errorf("failed to create a m2kignore file at the path %s . Error: %q", archExpDir, err)
	}
	if err := putM2KIgnore(archiveExpandedPath); err != nil { // TODO: is this necessary?
		return fmt.Errorf("failed to create a m2kignore file at the path %s . Error: %q", archiveExpandedPath, err)
	}
	// write the archive they uploaded
	f, err := os.OpenFile(archivePath, os.O_WRONLY|os.O_CREATE, DEFAULT_FILE_PERMISSIONS)
	if err != nil {
		return fmt.Errorf("failed to write the archive to the path %s . Error: %q", archivePath, err)
	}
	defer f.Close()
	if _, err := io.Copy(f, file); err != nil {
		return fmt.Errorf("failed to receive the archive file %s completely. Error: %q", workInput.Name, err)
	}
	// expand the archive
	if err := archiver.Unarchive(archivePath, archiveExpandedPath); err != nil {
		logrus.Debugf("failed to expand the archive at path %s into path %s . Trying other formats. Error: %q", archivePath, archiveExpandedPath, err)
		filename := workInput.Name
		if filepath.Ext(filename) == ".zip" {
			if err := archiver.NewZip().Unarchive(archivePath, archiveExpandedPath); err != nil {
				return fmt.Errorf("failed to expand the zip archive at path %s to the path %s . Error: %q", archivePath, archiveExpandedPath, err)
			}
		} else if filepath.Ext(filename) == ".tar" {
			if err := archiver.NewTar().Unarchive(archivePath, archiveExpandedPath); err != nil {
				return fmt.Errorf("failed to expand the tar archive at path %s to the path %s . Error: %q", archivePath, archiveExpandedPath, err)
			}
		} else if filepath.Ext(filename) == ".tgz" || strings.HasSuffix(filename, ".tar.gz") {
			if err := archiver.NewTarGz().Unarchive(archivePath, archiveExpandedPath); err != nil {
				return fmt.Errorf("failed to expand the tar.gz archive at path %s to the path %s . Error: %q", archivePath, archiveExpandedPath, err)
			}
		} else {
			return fmt.Errorf("the archive at path %s is not in a supported format. Please use one of the supported formats: %+v", archivePath, VALID_ARCHIVE_EXTS)
		}
	}
	return nil
}

func (fs *FileSystem) createProjectInput(t *bolt.Tx, workspaceId, projectId string, projInput types.ProjectInput, file io.Reader) error {
	// check conditions
	work, err := fs.readWorkspace(t, workspaceId)
	if err != nil {
		return err
	}
	project, err := fs.readProject(t, workspaceId, projectId)
	if err != nil {
		return err
	}
	if _, ok := project.Inputs[projInput.Id]; ok {
		return types.ErrorIdAlreadyInUse{Id: projInput.Id}
	}
	if projInput.Type != types.ProjectInputReference {
		for _, pi := range project.Inputs {
			if pi.NormalizedName == projInput.NormalizedName {
				reason := fmt.Sprintf("You have already uploaded an input with the filename '%s'. Please pick a different one.", projInput.NormalizedName)
				logrus.Debugf(reason)
				return types.ErrorValidation{Reason: reason}
			}
		}
		for _, pi := range work.Inputs {
			if pi.NormalizedName == projInput.NormalizedName {
				reason := fmt.Sprintf("You have already uploaded a workspace input with the filename '%s'. Please pick a different one.", projInput.NormalizedName)
				logrus.Debugf(reason)
				return types.ErrorValidation{Reason: reason}
			}
		}
	}
	if projInput.Type == types.ProjectInputReference {
		if _, ok := work.Inputs[projInput.Id]; !ok {
			return types.ErrorDoesNotExist{Id: projInput.Id}
		}
	}
	// update state
	project.Inputs[projInput.Id] = projInput
	project.Status[types.ProjectStatusStalePlan] = true
	lastDir := ""
	if projInput.Type == types.ProjectInputSources {
		project.Status[types.ProjectStatusInputSources] = true
		lastDir = SOURCES_DIR
	} else if projInput.Type == types.ProjectInputCustomizations {
		project.Status[types.ProjectStatusInputCustomizations] = true
		lastDir = CUSTOMIZATIONS_DIR
	} else if projInput.Type == types.ProjectInputConfigs {
		project.Status[types.ProjectStatusInputConfigs] = true
		lastDir = CONFIGS_DIR
	} else if projInput.Type == types.ProjectInputReference {
		project.Status[types.ProjectStatusInputReference] = true
	} else {
		return types.ErrorValidation{Reason: fmt.Sprintf("invalid project input type: %s", projInput.Type)}
	}
	if err := fs.updateProject(t, workspaceId, project); err != nil {
		return fmt.Errorf("failed to update the project with id: %s . Error: %q", projectId, err)
	}
	if projInput.Type == types.ProjectInputReference {
		return nil
	}
	// effects
	logrus.Debugf("creating a new input for the project %s with type %s and filename %s", projectId, projInput.Type, projInput.Name)
	projInputsDir := filepath.Join(common.Config.DataDir, PROJECTS_DIR, projectId, INPUTS_DIR)
	archDir := filepath.Join(projInputsDir, ARCHIVES_DIR, lastDir)
	archExpDir := filepath.Join(projInputsDir, EXPANDED_DIR, lastDir)
	archivePath := filepath.Join(archDir, projInput.NormalizedName)
	archiveExpandedPath := filepath.Join(archExpDir, projInput.NormalizedName)
	if err := os.RemoveAll(archivePath); err != nil {
		return fmt.Errorf("failed to remove the archive at path %s . Error: %q", archivePath, err)
	}
	if err := os.RemoveAll(archiveExpandedPath); err != nil {
		return fmt.Errorf("failed to remove the archive expanded directory at the path %s . Error: %q", archiveExpandedPath, err)
	}
	if projInput.Type == types.ProjectInputConfigs {
		// configs
		if err := os.MkdirAll(archExpDir, DEFAULT_DIRECTORY_PERMISSIONS); err != nil {
			return fmt.Errorf("failed to create a directory at the path %s . Error: %q", archExpDir, err)
		}
		// write the config file they uploaded
		f, err := os.OpenFile(archiveExpandedPath, os.O_WRONLY|os.O_CREATE, DEFAULT_FILE_PERMISSIONS)
		if err != nil {
			return fmt.Errorf("failed to write the config file to the path %s . Error: %q", archivePath, err)
		}
		defer f.Close()
		if _, err := io.Copy(f, file); err != nil {
			return fmt.Errorf("failed to receive and write the config file to the path %s completely. Error: %q", archiveExpandedPath, err)
		}
		return nil
	}
	// sources and customizations
	if err := os.MkdirAll(archDir, DEFAULT_DIRECTORY_PERMISSIONS); err != nil {
		return fmt.Errorf("failed to create the archive directory at the path %s . Error: %q", archDir, err)
	}
	if err := putM2KIgnore(archExpDir); err != nil { // also creates the directory if it doesn't exist, overwrites if it does exist
		return fmt.Errorf("failed to create a m2kignore file at the path %s . Error: %q", archExpDir, err)
	}
	if err := putM2KIgnore(archiveExpandedPath); err != nil { // TODO: is this necessary?
		return fmt.Errorf("failed to create a m2kignore file at the path %s . Error: %q", archiveExpandedPath, err)
	}
	// write the archive they uploaded
	f, err := os.OpenFile(archivePath, os.O_WRONLY|os.O_CREATE, DEFAULT_FILE_PERMISSIONS)
	if err != nil {
		return fmt.Errorf("failed to write the archive to the path %s . Error: %q", archivePath, err)
	}
	defer f.Close()
	if _, err := io.Copy(f, file); err != nil {
		return fmt.Errorf("failed to receive the archive file %s completely. Error: %q", projInput.Name, err)
	}
	// expand the archive
	if err := archiver.Unarchive(archivePath, archiveExpandedPath); err != nil {
		logrus.Debugf("failed to expand the archive at path %s into path %s . Trying other formats. Error: %q", archivePath, archiveExpandedPath, err)
		filename := projInput.Name
		if filepath.Ext(filename) == ".zip" {
			if err := archiver.NewZip().Unarchive(archivePath, archiveExpandedPath); err != nil {
				return fmt.Errorf("failed to expand the zip archive at path %s to the path %s . Error: %q", archivePath, archiveExpandedPath, err)
			}
		} else if filepath.Ext(filename) == ".tar" {
			if err := archiver.NewTar().Unarchive(archivePath, archiveExpandedPath); err != nil {
				return fmt.Errorf("failed to expand the tar archive at path %s to the path %s . Error: %q", archivePath, archiveExpandedPath, err)
			}
		} else if filepath.Ext(filename) == ".tgz" || strings.HasSuffix(filename, ".tar.gz") {
			if err := archiver.NewTarGz().Unarchive(archivePath, archiveExpandedPath); err != nil {
				return fmt.Errorf("failed to expand the tar.gz archive at path %s to the path %s . Error: %q", archivePath, archiveExpandedPath, err)
			}
		} else {
			return fmt.Errorf("the archive at path %s is not in a supported format. Please use one of the supported formats: %+v", archivePath, VALID_ARCHIVE_EXTS)
		}
	}
	return nil
}

// ReadProjectInput returns a project input
func (fs *FileSystem) ReadProjectInput(workspaceId, projectId, projInputId string, isCommon bool) (projInput types.ProjectInput, file io.Reader, err error) {
	db, err := fs.GetDatabase(true)
	if err != nil {
		return projInput, file, err
	}
	defer db.Close()
	err = db.View(func(t *bolt.Tx) error {
		if isCommon {
			projInput, file, err = fs.readWorkspaceInput(t, workspaceId, projInputId)
			return err
		}
		projInput, file, err = fs.readProjectInput(t, workspaceId, projectId, projInputId)
		return err
	})
	return projInput, file, err
}

func (fs *FileSystem) readWorkspaceInput(t *bolt.Tx, workspaceId, workInputId string) (workInput types.ProjectInput, file io.Reader, err error) {
	work, err := fs.readWorkspace(t, workspaceId)
	if err != nil {
		return types.ProjectInput{}, nil, err
	}
	workInput, ok := work.Inputs[workInputId]
	if !ok {
		return workInput, nil, types.ErrorDoesNotExist{Id: workInputId}
	}
	workInputsDir := filepath.Join(common.Config.DataDir, WORKSPACES_DIR, workspaceId, INPUTS_DIR)
	archivePath := ""
	if workInput.Type == types.ProjectInputSources {
		archivePath = filepath.Join(workInputsDir, ARCHIVES_DIR, SOURCES_DIR, workInput.NormalizedName)
	} else if workInput.Type == types.ProjectInputCustomizations {
		archivePath = filepath.Join(workInputsDir, ARCHIVES_DIR, CUSTOMIZATIONS_DIR, workInput.NormalizedName)
	} else if workInput.Type == types.ProjectInputConfigs {
		archivePath = filepath.Join(workInputsDir, EXPANDED_DIR, CONFIGS_DIR, workInput.NormalizedName)
	} else {
		return workInput, nil, types.ErrorValidation{Reason: fmt.Sprintf("invalid workspace input type: %s", workInput.Type)}
	}
	f, err := os.Open(archivePath)
	if err != nil {
		return workInput, nil, fmt.Errorf("failed to open the project input with id: %s at path %s . Error: %q", workInputId, archivePath, err)
	}
	return workInput, f, nil
}

func (fs *FileSystem) readProjectInput(t *bolt.Tx, workspaceId, projectId, projInputId string) (projInput types.ProjectInput, file io.Reader, err error) {
	project, err := fs.readProject(t, workspaceId, projectId)
	if err != nil {
		return types.ProjectInput{}, nil, err
	}
	projInput, ok := project.Inputs[projInputId]
	if !ok {
		return projInput, nil, types.ErrorDoesNotExist{Id: projInputId}
	}
	projInputsDir := filepath.Join(common.Config.DataDir, PROJECTS_DIR, projectId, INPUTS_DIR)
	archivePath := ""
	if projInput.Type == types.ProjectInputSources {
		archivePath = filepath.Join(projInputsDir, ARCHIVES_DIR, SOURCES_DIR, projInput.NormalizedName)
	} else if projInput.Type == types.ProjectInputCustomizations {
		archivePath = filepath.Join(projInputsDir, ARCHIVES_DIR, CUSTOMIZATIONS_DIR, projInput.NormalizedName)
	} else if projInput.Type == types.ProjectInputConfigs {
		archivePath = filepath.Join(projInputsDir, EXPANDED_DIR, CONFIGS_DIR, projInput.NormalizedName)
	} else if projInput.Type == types.ProjectInputReference {
		return fs.readWorkspaceInput(t, workspaceId, projInputId)
	} else {
		return projInput, nil, types.ErrorValidation{Reason: fmt.Sprintf("invalid project input type: %s", projInput.Type)}
	}
	f, err := os.Open(archivePath)
	if err != nil {
		return projInput, nil, fmt.Errorf("failed to open the project input with id: %s at path %s . Error: %q", projInputId, archivePath, err)
	}
	return projInput, f, nil
}

// DeleteProjectInput deletes the project input
func (fs *FileSystem) DeleteProjectInput(workspaceId, projectId, projInputId string, isCommon bool) error {
	db, err := fs.GetDatabase(false)
	if err != nil {
		return err
	}
	defer db.Close()
	return db.Update(func(t *bolt.Tx) error {
		if isCommon {
			// check conditions
			work, err := fs.readWorkspace(t, workspaceId)
			if err != nil {
				return err
			}
			workInputId := projInputId
			workInput, ok := work.Inputs[workInputId]
			if !ok {
				return types.ErrorDoesNotExist{Id: workInputId}
			}
			// update state
			delete(work.Inputs, workInputId)
			if err := fs.updateWorkspace(t, work); err != nil {
				return fmt.Errorf("failed to update project with id: %s . Error: %q", work.Id, err)
			}
			// effects
			projs, err := fs.listProjects(t, workspaceId)
			if err != nil {
				return err
			}
			for _, proj := range projs {
				if _, ok := proj.Inputs[workInputId]; !ok {
					continue
				}
				if err := fs.deleteProjectInput(t, workspaceId, proj.Id, workInputId); err != nil {
					return fmt.Errorf("failed to delete the reference to the workspace input '%s' from the project '%s' . Error: %q", workInputId, proj.Id, err)
				}
			}
			return fs.deleteWorkspaceInput(t, workspaceId, workInput)
		}
		return fs.deleteProjectInput(t, workspaceId, projectId, projInputId)
	})
}

func (fs *FileSystem) deleteWorkspaceInput(t *bolt.Tx, workspaceId string, workInput types.ProjectInput) error {
	workInputsDir := filepath.Join(common.Config.DataDir, WORKSPACES_DIR, workspaceId, INPUTS_DIR)
	archivePath := ""
	archiveExpandedPath := ""
	if workInput.Type == types.ProjectInputSources {
		archivePath = filepath.Join(workInputsDir, ARCHIVES_DIR, SOURCES_DIR, workInput.NormalizedName)
		archiveExpandedPath = filepath.Join(workInputsDir, EXPANDED_DIR, SOURCES_DIR, workInput.NormalizedName)
	} else if workInput.Type == types.ProjectInputCustomizations {
		archivePath = filepath.Join(workInputsDir, ARCHIVES_DIR, CUSTOMIZATIONS_DIR, workInput.NormalizedName)
		archiveExpandedPath = filepath.Join(workInputsDir, EXPANDED_DIR, CUSTOMIZATIONS_DIR, workInput.NormalizedName)
	} else if workInput.Type == types.ProjectInputConfigs {
		archiveExpandedPath = filepath.Join(workInputsDir, EXPANDED_DIR, CONFIGS_DIR, workInput.NormalizedName)
	} else {
		return types.ErrorValidation{Reason: fmt.Sprintf("invalid input type for workspace level input: %s", workInput.Type)}
	}
	if workInput.Type != types.ProjectInputConfigs {
		if err := os.RemoveAll(archivePath); err != nil {
			return fmt.Errorf("failed to delete the archive file with id: %s at path %s . Error: %q", workInput.Id, archivePath, err)
		}
	}
	if err := os.RemoveAll(archiveExpandedPath); err != nil {
		return fmt.Errorf("failed to delete the expanded archive directory/config file at path %s . Error: %q", archiveExpandedPath, err)
	}
	return nil
}

func (fs *FileSystem) deleteProjectInput(t *bolt.Tx, workspaceId, projectId, projInputId string) error {
	// check conditions
	project, err := fs.readProject(t, workspaceId, projectId)
	if err != nil {
		return err
	}
	projInput, ok := project.Inputs[projInputId]
	if !ok {
		return types.ErrorDoesNotExist{Id: projInputId}
	}
	// update state
	project.Status[types.ProjectStatusStalePlan] = true
	projInputsDir := filepath.Join(common.Config.DataDir, PROJECTS_DIR, projectId, INPUTS_DIR)
	archivePath := ""
	archiveExpandedPath := ""
	if projInput.Type == types.ProjectInputSources {
		archivePath = filepath.Join(projInputsDir, ARCHIVES_DIR, SOURCES_DIR, projInput.NormalizedName)
		archiveExpandedPath = filepath.Join(projInputsDir, EXPANDED_DIR, SOURCES_DIR, projInput.NormalizedName)
	} else if projInput.Type == types.ProjectInputCustomizations {
		archivePath = filepath.Join(projInputsDir, ARCHIVES_DIR, CUSTOMIZATIONS_DIR, projInput.NormalizedName)
		archiveExpandedPath = filepath.Join(projInputsDir, EXPANDED_DIR, CUSTOMIZATIONS_DIR, projInput.NormalizedName)
	} else if projInput.Type == types.ProjectInputConfigs {
		archiveExpandedPath = filepath.Join(projInputsDir, EXPANDED_DIR, CONFIGS_DIR, projInput.NormalizedName)
	} else if projInput.Type == types.ProjectInputReference {
		// there is no path that needs to be deleted for references since they are common to the workspace
	} else {
		return types.ErrorValidation{Reason: fmt.Sprintf("invalid project input type: %s", projInput.Type)}
	}
	delete(project.Inputs, projInputId)
	found := false
	for _, projInp := range project.Inputs {
		if projInp.Type == projInput.Type {
			found = true
			break
		}
	}
	if !found {
		if projInput.Type == types.ProjectInputSources {
			project.Status[types.ProjectStatusInputSources] = false
		} else if projInput.Type == types.ProjectInputCustomizations {
			project.Status[types.ProjectStatusInputCustomizations] = false
		} else if projInput.Type == types.ProjectInputConfigs {
			project.Status[types.ProjectStatusInputConfigs] = false
		} else {
			project.Status[types.ProjectStatusInputReference] = false
		}
	}
	if err := fs.updateProject(t, workspaceId, project); err != nil {
		return fmt.Errorf("failed to update project with id: %s . Error: %q", projectId, err)
	}
	if projInput.Type == types.ProjectInputReference {
		return nil
	}
	// effects
	if projInput.Type != types.ProjectInputConfigs {
		if err := os.RemoveAll(archivePath); err != nil {
			return fmt.Errorf("failed to delete the archive file with id: %s at path %s . Error: %q", projInputId, archivePath, err)
		}
	}
	if err := os.RemoveAll(archiveExpandedPath); err != nil {
		return fmt.Errorf("failed to delete the expanded archive directory/config file at path %s . Error: %q", archiveExpandedPath, err)
	}
	return nil
}

// StartPlanning starts the generation of a plan for a project.
// If plan generation is ongoing it will return an error.
func (fs *FileSystem) StartPlanning(workspaceId, projectId string, debugMode bool) error {
	logrus.Trace("FileSystem.StartPlanning start")
	defer logrus.Trace("FileSystem.StartPlanning end")
	db, err := fs.GetDatabase(false)
	if err != nil {
		logrus.Debugf("failed to get the database. Error: %q", err)
		return err
	}
	defer db.Close()
	return db.Update(func(t *bolt.Tx) error {
		return fs.startPlanning(t, workspaceId, projectId, debugMode)
	})
}

func (fs *FileSystem) startPlanning(t *bolt.Tx, workspaceId, projectId string, debugMode bool) error {
	logrus.Trace("FileSystem.startPlanning start")
	defer logrus.Trace("FileSystem.startPlanning end")
	// check conditions
	project, err := fs.readProject(t, workspaceId, projectId)
	if err != nil {
		return err
	}
	if project.Status[types.ProjectStatusPlanning] {
		return types.ErrorOngoing{Id: projectId}
	}

	if !project.Status[types.ProjectStatusInputSources] && !project.Status[types.ProjectStatusInputCustomizations] {
		if !project.Status[types.ProjectStatusInputReference] {
			return types.ErrorValidation{Reason: "the project has no source folders or customization folders as input"}
		}
		work, err := fs.readWorkspace(t, workspaceId)
		if err != nil {
			return err
		}
		found := false
		for _, inp := range project.Inputs {
			if inp.Type != types.ProjectInputReference {
				continue
			}
			actualInp := work.Inputs[inp.Id]
			if actualInp.Type == types.ProjectInputSources || actualInp.Type == types.ProjectInputCustomizations {
				found = true
				break
			}
		}
		if !found {
			return types.ErrorValidation{Reason: "the project has no source folders as input"}
		}
	}

	// update state
	logrus.Debugf("just before updating state before starting planning for project %s in workspace %s", projectId, workspaceId)
	project.Status[types.ProjectStatusPlanning] = true
	if err := fs.updateProject(t, workspaceId, project); err != nil {
		return fmt.Errorf("failed to update the project with id %s . Error: %q", projectId, err)
	}
	message := "Project: " + project.Id + ";"
	// This contains the metadata about a run (host and port of the plan progress server, etc.)
	planProgressServerMeta := types.QAServerMetadata{Host: common.Config.Host, Debug: debugMode}
	planProgressServerMeta.Port, err = freeport.GetFreePort()
	if err != nil {
		return fmt.Errorf("failed to get a free port. Error: %q", err)
	}
	logrus.Debugf("plan progress server metadata %+v", planProgressServerMeta)
	planProgressServerMetaBytes, err := json.Marshal(planProgressServerMeta)
	if err != nil {
		return fmt.Errorf("failed to marshal the plan progress server metdata: %+v . Error: %q", planProgressServerMeta, err)
	}
	planProgressBucket, err := t.CreateBucketIfNotExists([]byte(M2K_PLAN_PROGRESS_SERVER_METADATA_FILE))
	if err != nil {
		return fmt.Errorf("failed to create the bucket. Error: %q", err)
	}
	if err := planProgressBucket.Put([]byte(projectId), planProgressServerMetaBytes); err != nil {
		return fmt.Errorf("failed to save the plan progress metadata in the bucket '%s' for the project with id %s . Error: %q", M2K_PLAN_PROGRESS_SERVER_METADATA_FILE, projectId, err)
	}
	// effects
	logrus.Debugf("just before starting effects before starting planning for project %s in workspace %s", projectId, workspaceId)
	projInputsDir := filepath.Join(common.Config.DataDir, PROJECTS_DIR, projectId, INPUTS_DIR)
	currentRunDir, err := os.MkdirTemp("", fmt.Sprintf("plan-%s-*", projectId))
	if err != nil {
		return fmt.Errorf("failed to create a temporary directory to start planning. Error: %q", err)
	}

	// resolve symbolic links before proceeding
	currentRunDir, err = filepath.EvalSymlinks(currentRunDir)
	if err != nil {
		return fmt.Errorf("failed to resolve the temporary directory %s as a symbolic link. Error: %q", currentRunDir, err)
	}
	// default is empty string, if the input source is given, value is updated.
	currentRunSrcDir := ""
	if project.Status[types.ProjectStatusInputSources] {
		currentRunSrcDir = filepath.Join(currentRunDir, SOURCES_DIR)
		currentRunSrcDirSrc := filepath.Join(projInputsDir, EXPANDED_DIR, SOURCES_DIR)
		if err := copyDir(currentRunSrcDirSrc, currentRunSrcDir); err != nil {
			return fmt.Errorf("failed to copy the sources directory from %s to %s for the current run. Error: %q", currentRunSrcDirSrc, currentRunSrcDir, err)
		}
	}
	currentRunCustDir := ""
	if project.Status[types.ProjectStatusInputCustomizations] {
		currentRunCustDir = filepath.Join(currentRunDir, CUSTOMIZATIONS_DIR)
		currentRunCustDirSrc := filepath.Join(projInputsDir, EXPANDED_DIR, CUSTOMIZATIONS_DIR)
		if err := copyDir(currentRunCustDirSrc, currentRunCustDir); err != nil {
			return fmt.Errorf("failed to copy the customizations directory from %s to %s for the current run. Error: %q", currentRunCustDirSrc, currentRunCustDir, err)
		}
	}
	currentRunConfigsDir := filepath.Join(currentRunDir, CONFIGS_DIR)
	var currentRunConfigPaths []string = nil
	if project.Status[types.ProjectStatusInputConfigs] {
		currentRunConfigsDirSrc := filepath.Join(projInputsDir, EXPANDED_DIR, CONFIGS_DIR)
		if err := copyDir(currentRunConfigsDirSrc, currentRunConfigsDir); err != nil {
			return fmt.Errorf("failed to copy the configs directory from %s to %s for the current run. Error: %q", currentRunConfigsDirSrc, currentRunConfigsDir, err)
		}
		currentRunConfigPaths, err = getConfigPaths(currentRunConfigsDir, project)
		if err != nil {
			return fmt.Errorf("failed to get the config paths from the directory %s . Error: %q", currentRunConfigsDir, err)
		}
	}
	// copy over common workspace level inputs
	logrus.Debugf("just before copying over reference type inputs before starting planning for project %s in workspace %s", projectId, workspaceId)
	if project.Status[types.ProjectStatusInputReference] {
		work, err := fs.readWorkspace(t, workspaceId)
		if err != nil {
			return err
		}
		workInputsDir := filepath.Join(common.Config.DataDir, WORKSPACES_DIR, workspaceId, INPUTS_DIR, EXPANDED_DIR)
		commonConfigPaths := []string{}
		for _, inp := range project.Inputs {
			if inp.Type != types.ProjectInputReference {
				continue
			}
			inpPathSrc := ""
			inpPathDst := ""
			workInp := work.Inputs[inp.Id]
			if workInp.Type == types.ProjectInputSources {
				inpPathSrc = filepath.Join(workInputsDir, SOURCES_DIR, workInp.NormalizedName)
				inpPathDst = filepath.Join(currentRunSrcDir, workInp.NormalizedName)
				if err := os.MkdirAll(currentRunSrcDir, DEFAULT_DIRECTORY_PERMISSIONS); err != nil {
					return fmt.Errorf("failed to create the sources directory at the path %s . Error: %q", currentRunSrcDir, err)
				}
				if err := copyDir(inpPathSrc, inpPathDst); err != nil {
					return fmt.Errorf("failed to copy the reference sources directory from %s to %s for the current run. Error: %q", inpPathSrc, inpPathDst, err)
				}
			}
			if workInp.Type == types.ProjectInputCustomizations {
				currentRunCustDir = filepath.Join(currentRunDir, CUSTOMIZATIONS_DIR)
				inpPathSrc = filepath.Join(workInputsDir, CUSTOMIZATIONS_DIR, workInp.NormalizedName)
				inpPathDst = filepath.Join(currentRunCustDir, workInp.NormalizedName)
				if err := os.MkdirAll(currentRunCustDir, DEFAULT_DIRECTORY_PERMISSIONS); err != nil {
					return fmt.Errorf("failed to create the customizations directory at the path %s . Error: %q", currentRunCustDir, err)
				}
				if err := copyDir(inpPathSrc, inpPathDst); err != nil {
					return fmt.Errorf("failed to copy the reference customizations directory from %s to %s for the current run. Error: %q", inpPathSrc, inpPathDst, err)
				}
			}
			if workInp.Type == types.ProjectInputConfigs {
				inpPathSrc = filepath.Join(workInputsDir, CONFIGS_DIR, workInp.NormalizedName)
				inpPathDst = filepath.Join(currentRunConfigsDir, workInp.NormalizedName)
				if err := os.MkdirAll(currentRunConfigsDir, DEFAULT_DIRECTORY_PERMISSIONS); err != nil {
					return fmt.Errorf("failed to create the configs directory at the path %s . Error: %q", currentRunConfigsDir, err)
				}
				if err := CopyFile(inpPathDst, inpPathSrc); err != nil {
					return fmt.Errorf("failed to copy the reference configs file from %s to %s for the current run. Error: %q", inpPathSrc, inpPathDst, err)
				}
				commonConfigPaths = append(commonConfigPaths, inpPathDst)
			}
		}
		currentRunConfigPaths = append(commonConfigPaths, currentRunConfigPaths...)
	}
	// start plan generation
	logrus.Debugf("just before starting planning for project %s in workspace %s", projectId, workspaceId)
	go fs.runPlan(currentRunDir, currentRunConfigPaths, currentRunSrcDir, currentRunCustDir, currentRunDir, message, planProgressServerMeta.Port, workspaceId, projectId, project.Name, debugMode)
	logrus.Infof("Planning started for the project with id %s", projectId)
	return nil
}

// ReadPlan returns the plan for a project
func (fs *FileSystem) ReadPlan(workspaceId, projectId string) (file io.Reader, err error) {
	db, err := fs.GetDatabase(true)
	if err != nil {
		return nil, err
	}
	defer db.Close()
	var f io.Reader
	err = db.View(func(t *bolt.Tx) error {
		f, err = fs.readPlan(t, workspaceId, projectId)
		return err
	})
	return f, err
}

func (fs *FileSystem) readPlan(t *bolt.Tx, workspaceId, projectId string) (file io.Reader, err error) {
	project, err := fs.readProject(t, workspaceId, projectId)
	if err != nil {
		return nil, err
	}
	// check lock
	currentRunDir := filepath.Join(common.Config.DataDir, PROJECTS_DIR, projectId, INPUTS_DIR, EXPANDED_DIR)
	if project.Status[types.ProjectStatusPlanning] {
		planBucket := t.Bucket([]byte(M2K_PLAN_PROGRESS_SERVER_METADATA_FILE))
		if planBucket == nil {
			return nil, fmt.Errorf("failed to open the plan progress bucket. Error: %q", err)
		}
		planProgressServerMetaBytes := planBucket.Get([]byte(projectId))
		if planProgressServerMetaBytes == nil {
			return nil, fmt.Errorf("the project id %s is missing from the plan progress bucket '%s'", projectId, M2K_PLAN_PROGRESS_SERVER_METADATA_FILE)
		}
		meta := types.QAServerMetadata{}
		if err := json.Unmarshal(planProgressServerMetaBytes, &meta); err != nil {
			logrus.Errorf("failed to unmarshal the plan progress metadata as json. Actual: %s \nError: %q", string(planProgressServerMetaBytes), err)
			return nil, types.ErrorOngoing{Id: projectId}
		}
		proURL := fmt.Sprintf("http://%s:%d/progress", meta.Host, meta.Port)
		resp, err := resty.New().R().SetHeader("Accept", common.CONTENT_TYPE_JSON).Get(proURL)
		if err != nil {
			logrus.Errorf("failed to send a GET request to get the plan progress from the server at %s . Error: %q", proURL, err)
			return nil, types.ErrorOngoing{Id: projectId}
		}
		return bytes.NewBuffer(resp.Body()), types.ErrorOngoing{Id: projectId}
	}
	if !project.Status[types.ProjectStatusPlan] {
		if project.Status[types.ProjectStatusPlanError] {
			return nil, types.ErrorValidation{Reason: "either planning was cancelled or the timeout was exceeded"}
		}
		return nil, types.ErrorDoesNotExist{Id: projectId}
	}
	planFilePath := filepath.Join(currentRunDir, M2K_PLAN_FILENAME)
	f, err := os.Open(planFilePath)
	if err != nil {
		return nil, fmt.Errorf("failed to open the plan file at path %s . Error: %q", planFilePath, err)
	}
	return f, nil
}

// UpdatePlan updates the plan file for a project
func (fs *FileSystem) UpdatePlan(workspaceId, projectId string, plan io.Reader) error {
	db, err := fs.GetDatabase(false)
	if err != nil {
		return err
	}
	defer db.Close()
	return db.Update(func(t *bolt.Tx) error {
		return fs.updatePlan(t, workspaceId, projectId, plan)
	})
}

func (fs *FileSystem) updatePlan(t *bolt.Tx, workspaceId, projectId string, plan io.Reader) error {
	// check conditions
	project, err := fs.readProject(t, workspaceId, projectId)
	if err != nil {
		return err
	}
	// check lock
	if !project.Status[types.ProjectStatusInputSources] {
		if !project.Status[types.ProjectStatusInputReference] {
			return types.ErrorValidation{Reason: "the project does not have any folders with source code. Please upload sources before updating the plan"}
		}
		work, err := fs.readWorkspace(t, workspaceId)
		if err != nil {
			return err
		}
		found := false
		for _, inp := range project.Inputs {
			if inp.Type != types.ProjectInputReference {
				continue
			}
			actualInp := work.Inputs[inp.Id]
			if actualInp.Type == types.ProjectInputSources {
				found = true
				break
			}
		}
		if !found {
			return types.ErrorValidation{Reason: "the project does not have any folders with source code. Please upload sources before updating the plan"}
		}
	}
	if project.Status[types.ProjectStatusPlanning] {
		return types.ErrorOngoing{Id: projectId}
	}
	planBytes, err := io.ReadAll(plan)
	if err != nil {
		return fmt.Errorf("failed to read the plan. Error: %q", err)
	}
	if _, err := validateAndProcessPlan(string(planBytes), false); err != nil {
		return types.ErrorValidation{Reason: fmt.Sprintf("plan validation failed. Error: %q", err)}
	}
	// update state
	project.Status[types.ProjectStatusPlan] = true
	project.Status[types.ProjectStatusStalePlan] = false
	project.Status[types.ProjectStatusPlanError] = false
	if err := fs.updateProject(t, workspaceId, project); err != nil {
		return fmt.Errorf("failed to update the project %s in the workspace %s . Error: %q", projectId, workspaceId, err)
	}
	// effects
	planFilePath := filepath.Join(common.Config.DataDir, PROJECTS_DIR, projectId, INPUTS_DIR, EXPANDED_DIR, M2K_PLAN_FILENAME)
	if err := os.WriteFile(planFilePath, planBytes, DEFAULT_FILE_PERMISSIONS); err != nil {
		return fmt.Errorf("failed to write to the plan file at path %s . Error: %q", planFilePath, err)
	}
	return nil
}

// DeletePlan deletes plan for a project
func (fs *FileSystem) DeletePlan(workspaceId, projectId string) error {
	db, err := fs.GetDatabase(false)
	if err != nil {
		return err
	}
	defer db.Close()
	return db.Update(func(t *bolt.Tx) error {
		return fs.deletePlan(t, workspaceId, projectId)
	})
}

func (fs *FileSystem) deletePlan(t *bolt.Tx, workspaceId, projectId string) error {
	// check conditions
	project, err := fs.readProject(t, workspaceId, projectId)
	if err != nil {
		return err
	}
	if !project.Status[types.ProjectStatusPlan] {
		return types.ErrorValidation{Reason: "the project has no plan yet. Generate a plan first."}
	}
	// check lock
	if project.Status[types.ProjectStatusPlanning] {
		// TODO: allow stopping ongoing plan generation
		return types.ErrorOngoing{Id: projectId}
	}
	// update state
	project.Status[types.ProjectStatusPlan] = false
	if err := fs.updateProject(t, workspaceId, project); err != nil {
		return fmt.Errorf("failed to update the project with id %s . Error: %q", projectId, err)
	}
	// effects
	planFilePath := filepath.Join(common.Config.DataDir, PROJECTS_DIR, projectId, INPUTS_DIR, EXPANDED_DIR, M2K_PLAN_FILENAME)
	if err := os.RemoveAll(planFilePath); err != nil {
		return fmt.Errorf("failed to delete the plan file at path %s . Error: %q", planFilePath, err)
	}
	return nil
}

// ResumeTransformation resumes a transformation that did not finish
func (fs *FileSystem) ResumeTransformation(workspaceId, projectId, projOutputId string, debugMode bool) error {
	db, err := fs.GetDatabase(false)
	if err != nil {
		return err
	}
	defer db.Close()
	return db.Update(func(t *bolt.Tx) error {
		return fs.resumeTransformation(t, workspaceId, projectId, projOutputId, debugMode)
	})
}

func (fs *FileSystem) resumeTransformation(t *bolt.Tx, workspaceId, projectId, projOutputId string, debugMode bool) error {
	// check conditions
	project, err := fs.readProject(t, workspaceId, projectId)
	if err != nil {
		return err
	}
	projOutput, ok := project.Outputs[projOutputId]
	if !ok {
		return types.ErrorDoesNotExist{Id: projOutputId}
	}
	if projOutput.Status == types.ProjectOutputStatusDoneSuccess {
		logrus.Debugf("the transformation for output %s of project %s already finished", projOutputId, projectId)
		return nil
	}
	if projOutput.Status != types.ProjectOutputStatusInProgress {
		return fmt.Errorf("expected the project output to be in status '%s' . Actual: %+v", types.ProjectOutputStatusInProgress, projOutput)
	}
	qaServerBucket := t.Bucket([]byte(M2K_QA_SERVER_METADATA_FILE))
	if qaServerBucket == nil {
		return fmt.Errorf("the qa server metadata bucket is missing")
	}
	qaServerMetaBytes := qaServerBucket.Get([]byte(projOutputId))
	if qaServerMetaBytes == nil {
		return fmt.Errorf("the qa server metadata is missing for the output %s of project with id %s", projOutputId, projectId)
	}
	currentRunDir := filepath.Join(common.Config.DataDir, PROJECTS_DIR, projectId, PROJECT_OUTPUTS_DIR, projOutputId)
	qaServerMeta := types.QAServerMetadata{}
	if err := json.Unmarshal(qaServerMetaBytes, &qaServerMeta); err != nil {
		logrus.Errorf("failed to unmarshal the qa server metadata as json. Actual: %s\nError: %q", string(qaServerMetaBytes), err)
		return err
	}
	if _, err := http.Get(fmt.Sprintf("http://%s:%d", qaServerMeta.Host, qaServerMeta.Port)); err == nil {
		return types.ErrorOngoing{Id: projOutputId}
	}
	// update state
	// resume the transformation
	qaServerMeta.Host = common.Config.Host
	qaServerMeta.Port, err = freeport.GetFreePort()
	if err != nil {
		return fmt.Errorf("failed to get a free port. Error: %q", err)
	}
	qaServerMeta.Debug = debugMode || qaServerMeta.Debug
	if qaServerMetaBytes, err = json.Marshal(qaServerMeta); err != nil {
		return fmt.Errorf("failed to marshal to the qa server metadata as json. Actual: %+v\nError: %q", qaServerMeta, err)
	}
	if err := qaServerBucket.Put([]byte(projOutputId), qaServerMetaBytes); err != nil {
		return fmt.Errorf("failed to update the qa server metadata in the bucket. Error: %q", err)
	}
	currentRunSrcDir := ""
	if project.Status[types.ProjectStatusInputSources] {
		currentRunSrcDir = filepath.Join(currentRunDir, SOURCES_DIR)
	}
	currentRunCustDir := ""
	if project.Status[types.ProjectStatusInputCustomizations] {
		currentRunCustDir = filepath.Join(currentRunDir, CUSTOMIZATIONS_DIR)
	}
	currentRunOutDir := filepath.Join(currentRunDir, "output")
	message := "Project: " + projectId + "; Output:" + projOutputId + ";"
	transformCh := make(chan error, 2)
	currentRunConfigsDir := filepath.Join(currentRunDir, CONFIGS_DIR)
	var currentRunConfigPaths []string = nil
	if project.Status[types.ProjectStatusInputConfigs] {
		currentRunConfigPaths, err = getConfigPaths(currentRunConfigsDir, project)
		if err != nil {
			return fmt.Errorf("failed to get the config paths from the directory %s . Error: %q", currentRunConfigsDir, err)
		}
	}
	if project.Status[types.ProjectStatusInputReference] {
		work, err := fs.readWorkspace(t, workspaceId)
		if err != nil {
			return err
		}
		commonConfigPaths := []string{}
		for _, inp := range project.Inputs {
			if inp.Type != types.ProjectInputReference {
				continue
			}
			workInp := work.Inputs[inp.Id]
			if workInp.Type == types.ProjectInputConfigs {
				commonConfigPaths = append(commonConfigPaths, filepath.Join(currentRunConfigsDir, workInp.NormalizedName))
			}
		}
		currentRunConfigPaths = append(commonConfigPaths, currentRunConfigPaths...)
	}
	// resume the transformation
	go fs.runTransform(currentRunDir, currentRunConfigPaths, currentRunSrcDir, currentRunCustDir, currentRunOutDir, message, qaServerMeta.Port, transformCh, workspaceId, projectId, projOutput, debugMode, true)
	return nil
}

// StartTransformation starts the transformation for a project.
func (fs *FileSystem) StartTransformation(workspaceId, projectId string, projOutput types.ProjectOutput, plan io.Reader, debugMode bool) error {
	db, err := fs.GetDatabase(false)
	if err != nil {
		return err
	}
	defer db.Close()
	return db.Update(func(t *bolt.Tx) error {
		return fs.startTransformation(t, workspaceId, projectId, projOutput, plan, debugMode)
	})
}

func (fs *FileSystem) startTransformation(t *bolt.Tx, workspaceId, projectId string, projOutput types.ProjectOutput, plan io.Reader, debugMode bool) error {
	// check conditions
	project, err := fs.readProject(t, workspaceId, projectId)
	if err != nil {
		return err
	}
	if _, ok := project.Outputs[projOutput.Id]; ok {
		return types.ErrorIdAlreadyInUse{Id: projOutput.Id}
	}
	if !project.Status[types.ProjectStatusInputSources] && !project.Status[types.ProjectStatusInputCustomizations] {
		if !project.Status[types.ProjectStatusInputReference] {
			return types.ErrorValidation{Reason: "the project has no source or customization folders as input"}
		}
		work, err := fs.readWorkspace(t, workspaceId)
		if err != nil {
			return err
		}
		found := false
		for _, inp := range project.Inputs {
			if inp.Type != types.ProjectInputReference {
				continue
			}
			actualInp := work.Inputs[inp.Id]
			if actualInp.Type == types.ProjectInputSources || actualInp.Type == types.ProjectInputCustomizations {
				found = true
				break
			}
		}
		if !found {
			return types.ErrorValidation{Reason: "the project has no source or customization folders as input"}
		}
	}
	if !project.Status[types.ProjectStatusPlan] {
		return types.ErrorValidation{Reason: "the project has no plan"}
	}
	projInputsDir := filepath.Join(common.Config.DataDir, PROJECTS_DIR, projectId, INPUTS_DIR)
	var planBytes []byte
	if plan == nil {
		srcPlanPath := filepath.Join(projInputsDir, EXPANDED_DIR, M2K_PLAN_FILENAME)
		planBytes, err = os.ReadFile(srcPlanPath)
		if err != nil {
			err := fmt.Errorf("failed to read the plan file at path %s . Error: %q", srcPlanPath, err)
			logrus.Error(err)
			if os.IsNotExist(err) {
				return types.ErrorDoesNotExist{Id: "plan"}
			}
			return err
		}
	} else {
		planBytes, err = io.ReadAll(plan)
		if err != nil {
			return fmt.Errorf("failed to read the plan. Error: %q", err)
		}
	}
	planStr, err := validateAndProcessPlan(string(planBytes), true)
	if err != nil {
		return types.ErrorValidation{Reason: err.Error()}
	}
	// update state
	project.Outputs[projOutput.Id] = projOutput
	project.Status[types.ProjectStatusOutputs] = true
	if err := fs.updateProject(t, workspaceId, project); err != nil {
		return fmt.Errorf("failed to update the project with id %s . Error: %q", projectId, err)
	}
	// This file contains the metadata about a run (host and port of the QA engine's http server, etc.)
	qaServerMeta := types.QAServerMetadata{Host: common.Config.Host, Debug: debugMode}
	qaServerMeta.Port, err = freeport.GetFreePort()
	if err != nil {
		return fmt.Errorf("failed to get a free port. Error: %q", err)
	}
	logrus.Debugf("qa server metadata %+v", qaServerMeta)
	qaServerBucket, err := t.CreateBucketIfNotExists([]byte(M2K_QA_SERVER_METADATA_FILE))
	if err != nil {
		return fmt.Errorf("failed to create/get the bucket for qa server metadata . Error: %q", err)
	}
	qaServerMetaBytes, err := json.Marshal(qaServerMeta)
	if err != nil {
		return fmt.Errorf("failed to marshal the qa server metadata to json. Actual: %+v\nError: %q", qaServerMeta, err)
	}
	if err := qaServerBucket.Put([]byte(projOutput.Id), qaServerMetaBytes); err != nil {
		return fmt.Errorf("failed to update the qa server metadata in the bucket. Error: %q", err)
	}
	// effects
	currentRunDir := filepath.Join(common.Config.DataDir, PROJECTS_DIR, projectId, PROJECT_OUTPUTS_DIR, projOutput.Id)
	if err := os.MkdirAll(currentRunDir, DEFAULT_DIRECTORY_PERMISSIONS); err != nil {
		return fmt.Errorf("failed to make the project output directory at path %s . Error: %q", currentRunDir, err)
	}
	planPath := filepath.Join(currentRunDir, M2K_PLAN_FILENAME)
	if err := os.WriteFile(planPath, []byte(planStr), DEFAULT_FILE_PERMISSIONS); err != nil {
		return fmt.Errorf("failed to write the plan to a file at path %s . Error: %q", planPath, err)
	}
	// default is empty string, if the input source is given, the value is updated
	currentRunSrcDir := ""
	// copy the source and customizations directories into the run directory
	if project.Status[types.ProjectStatusInputSources] {
		currentRunSrcDir = filepath.Join(currentRunDir, SOURCES_DIR)
		srcPath := filepath.Join(projInputsDir, EXPANDED_DIR, SOURCES_DIR)
		if err := copyDir(srcPath, currentRunSrcDir); err != nil {
			return fmt.Errorf("failed to copy the sources directory from %s to %s for the current run. Error: %q", srcPath, currentRunSrcDir, err)
		}
	}
	currentRunCustDir := ""
	if project.Status[types.ProjectStatusInputCustomizations] {
		custPath := filepath.Join(projInputsDir, EXPANDED_DIR, CUSTOMIZATIONS_DIR)
		currentRunCustDir = filepath.Join(currentRunDir, CUSTOMIZATIONS_DIR)
		if err := copyDir(custPath, currentRunCustDir); err != nil {
			return fmt.Errorf("failed to copy the customizations directory from %s to %s for the current run. Error: %q", custPath, currentRunCustDir, err)
		}
	}
	currentRunConfigsDir := filepath.Join(currentRunDir, CONFIGS_DIR)
	var currentRunConfigPaths []string = nil
	if project.Status[types.ProjectStatusInputConfigs] {
		configsPath := filepath.Join(projInputsDir, EXPANDED_DIR, CONFIGS_DIR)
		if err := copyDir(configsPath, currentRunConfigsDir); err != nil {
			return fmt.Errorf("failed to copy the customizations directory from %s to %s for the current run. Error: %q", configsPath, currentRunConfigsDir, err)
		}
		currentRunConfigPaths, err = getConfigPaths(currentRunConfigsDir, project)
		if err != nil {
			return fmt.Errorf("failed to get the config paths from the directory %s . Error: %q", currentRunConfigsDir, err)
		}
	}
	currentRunOutDir := filepath.Join(currentRunDir, "output")
	message := "Project: " + projectId + "; Output:" + projOutput.Id + ";"
	transformCh := make(chan error, 2)
	// get common workspace level inputs
	if project.Status[types.ProjectStatusInputReference] {
		work, err := fs.readWorkspace(t, workspaceId)
		if err != nil {
			return err
		}
		workInputsDir := filepath.Join(common.Config.DataDir, WORKSPACES_DIR, workspaceId, INPUTS_DIR, EXPANDED_DIR)
		commonConfigPaths := []string{}
		for _, inp := range project.Inputs {
			if inp.Type != types.ProjectInputReference {
				continue
			}
			inpPathSrc := ""
			inpPathDst := ""
			workInp := work.Inputs[inp.Id]
			if workInp.Type == types.ProjectInputSources {
				inpPathSrc = filepath.Join(workInputsDir, SOURCES_DIR, workInp.NormalizedName)
				inpPathDst = filepath.Join(currentRunSrcDir, workInp.NormalizedName)
				if err := os.MkdirAll(currentRunSrcDir, DEFAULT_DIRECTORY_PERMISSIONS); err != nil {
					return fmt.Errorf("failed to create the sources directory at the path %s . Error: %q", currentRunSrcDir, err)
				}
				if err := copyDir(inpPathSrc, inpPathDst); err != nil {
					return fmt.Errorf("failed to copy the reference sources directory from path %s to %s . Error: %q", inpPathSrc, inpPathDst, err)
				}
			}
			if workInp.Type == types.ProjectInputCustomizations {
				currentRunCustDir = filepath.Join(currentRunDir, CUSTOMIZATIONS_DIR)
				inpPathSrc = filepath.Join(workInputsDir, CUSTOMIZATIONS_DIR, workInp.NormalizedName)
				inpPathDst = filepath.Join(currentRunCustDir, workInp.NormalizedName)
				if err := os.MkdirAll(currentRunCustDir, DEFAULT_DIRECTORY_PERMISSIONS); err != nil {
					return fmt.Errorf("failed to create the customizations directory at the path %s . Error: %q", currentRunCustDir, err)
				}
				if err := copyDir(inpPathSrc, inpPathDst); err != nil {
					return fmt.Errorf("failed to copy the reference customizations directory from path %s to %s . Error: %q", inpPathSrc, inpPathDst, err)
				}
			}
			if workInp.Type == types.ProjectInputConfigs {
				inpPathSrc = filepath.Join(workInputsDir, CONFIGS_DIR, workInp.NormalizedName)
				inpPathDst = filepath.Join(currentRunConfigsDir, workInp.NormalizedName)
				if err := os.MkdirAll(currentRunConfigsDir, DEFAULT_DIRECTORY_PERMISSIONS); err != nil {
					return fmt.Errorf("failed to create the configs directory at the path %s . Error: %q", currentRunConfigsDir, err)
				}
				if err := CopyFile(inpPathDst, inpPathSrc); err != nil {
					return fmt.Errorf("failed to copy the reference config file from path %s to %s . Error: %q", inpPathSrc, inpPathDst, err)
				}
				commonConfigPaths = append(commonConfigPaths, inpPathDst)
			}
		}
		currentRunConfigPaths = append(commonConfigPaths, currentRunConfigPaths...)
	}
	// start the transformation
	go fs.runTransform(currentRunDir, currentRunConfigPaths, currentRunSrcDir, currentRunCustDir, currentRunOutDir, message, qaServerMeta.Port, transformCh, workspaceId, projectId, projOutput, debugMode, false)
	logrus.Infof("Waiting for QA engine to start for the output %s of the project %s", projOutput.Id, projectId)
	if err := <-transformCh; err != nil {
		return fmt.Errorf("failed to start the transformation and qa engine. Error: %q", err)
	}
	logrus.Infof("Transformation and QA engine has started for output %s of project %s at port %d", projOutput.Id, projectId, qaServerMeta.Port)
	return nil
}

// ReadProjectOutput returns the target artifacts for an application
func (fs *FileSystem) ReadProjectOutput(workspaceId, projectId, projOutputId string) (projOutput types.ProjectOutput, file io.Reader, err error) {
	db, err := fs.GetDatabase(true)
	if err != nil {
		return projOutput, file, err
	}
	defer db.Close()
	err = db.View(func(t *bolt.Tx) error {
		projOutput, file, err = fs.readProjectOutput(t, workspaceId, projectId, projOutputId)
		return err
	})
	return projOutput, file, err
}

func (fs *FileSystem) readProjectOutput(t *bolt.Tx, workspaceId, projectId, projOutputId string) (projOutput types.ProjectOutput, file io.Reader, err error) {
	project, err := fs.readProject(t, workspaceId, projectId)
	if err != nil {
		return types.ProjectOutput{}, nil, err
	}
	projOutput, ok := project.Outputs[projOutputId]
	if !ok {
		return projOutput, nil, types.ErrorDoesNotExist{Id: projOutputId}
	}
	if projOutput.Status == types.ProjectOutputStatusInProgress {
		return projOutput, nil, types.ErrorOngoing{Id: projOutputId}
	}
	if projOutput.Status != types.ProjectOutputStatusDoneSuccess {
		if projOutput.Status == types.ProjectOutputStatusDoneError {
			return projOutput, nil, types.ErrorValidation{Reason: fmt.Sprintf("an error occurred during transformation of the output %s of project %s", projOutputId, projectId)}
		}
		return projOutput, nil, types.ErrorDoesNotExist{Id: projOutputId}
	}
	projOutputPath := filepath.Join(common.Config.DataDir, PROJECTS_DIR, projectId, PROJECT_OUTPUTS_DIR, projOutputId, "output.zip")
	f, err := os.Open(projOutputPath)
	if err != nil {
		return projOutput, nil, fmt.Errorf("failed to read the project output file at path %s . Error: %q", projOutputPath, err)
	}
	return projOutput, f, nil
}

// ReadProjectOutputGraph returns the graph file from the target artifacts for an application
func (fs *FileSystem) ReadProjectOutputGraph(workspaceId, projectId, projOutputId string) (projOutput types.ProjectOutput, file io.Reader, err error) {
	db, err := fs.GetDatabase(true)
	if err != nil {
		return projOutput, file, err
	}
	defer db.Close()
	err = db.View(func(t *bolt.Tx) error {
		projOutput, file, err = fs.readProjectOutputGraph(t, workspaceId, projectId, projOutputId)
		return err
	})
	return projOutput, file, err
}

func (fs *FileSystem) readProjectOutputGraph(t *bolt.Tx, workspaceId, projectId, projOutputId string) (projOutput types.ProjectOutput, file io.Reader, err error) {
	project, err := fs.readProject(t, workspaceId, projectId)
	if err != nil {
		return types.ProjectOutput{}, nil, err
	}
	projOutput, ok := project.Outputs[projOutputId]
	if !ok {
		return projOutput, nil, types.ErrorDoesNotExist{Id: projOutputId}
	}
	if projOutput.Status == types.ProjectOutputStatusInProgress {
		return projOutput, nil, types.ErrorOngoing{Id: projOutputId}
	}
	if projOutput.Status != types.ProjectOutputStatusDoneSuccess {
		if projOutput.Status == types.ProjectOutputStatusDoneError {
			return projOutput, nil, types.ErrorValidation{Reason: fmt.Sprintf("an error occurred during transformation of the output %s of project %s", projOutputId, projectId)}
		}
		return projOutput, nil, types.ErrorDoesNotExist{Id: projOutputId}
	}
	curDir := filepath.Join(common.Config.DataDir, PROJECTS_DIR, projectId, PROJECT_OUTPUTS_DIR, projOutputId, "output")
	if err := fs.processGraph(curDir); err != nil {
		return projOutput, nil, fmt.Errorf("failed to process the project output graph file inside the output directory %s . Error: %q", curDir, err)
	}
	projOutputPath := filepath.Join(curDir, "m2k-proc-graph.json")
	f, err := os.Open(projOutputPath)
	if err != nil {
		return projOutput, nil, fmt.Errorf("failed to read the project output file at path %s . Error: %q", projOutputPath, err)
	}
	return projOutput, f, nil
}

func (fs *FileSystem) processGraph(currentRunDir string) error {
	logrus.Infof("Starting graph at directory %s", currentRunDir)
	cmdArgs := []string{"graph", "--output", "m2k-proc-graph.json"}
	logrus.Infof("graph cmdArgs: %+v", cmdArgs)
	ctx := context.Background()
	if common.Config.PlanTimeoutSeconds > 0 {
		var cancel context.CancelFunc
		ctx, cancel = context.WithTimeout(ctx, time.Duration(common.Config.PlanTimeoutSeconds)*time.Second)
		defer cancel()
	}
	cmd := exec.CommandContext(ctx, common.APP_NAME, cmdArgs...)
	cmd.Dir = currentRunDir
	if err := cmd.Run(); err != nil {
		return fmt.Errorf("failed to start the graph command. Error: %q", err)
	}
	return nil
}

// DeleteProjectOutput deletes the project output
func (fs *FileSystem) DeleteProjectOutput(workspaceId, projectId, projOutputId string) error {
	db, err := fs.GetDatabase(false)
	if err != nil {
		return err
	}
	defer db.Close()
	return db.Update(func(t *bolt.Tx) error {
		return fs.deleteProjectOutput(t, workspaceId, projectId, projOutputId)
	})
}

func (fs *FileSystem) deleteProjectOutput(t *bolt.Tx, workspaceId, projectId, projOutputId string) error {
	// check conditions
	project, err := fs.readProject(t, workspaceId, projectId)
	if err != nil {
		return err
	}
	projOutput, ok := project.Outputs[projOutputId]
	if !ok {
		return types.ErrorDoesNotExist{Id: projOutputId}
	}
	if projOutput.Status == types.ProjectOutputStatusInProgress {
		// TODO: implement ability to cancel ongoing transformation
		return types.ErrorOngoing{Id: projOutputId}
	}
	// update state
	delete(project.Outputs, projOutputId)
	if len(project.Outputs) == 0 {
		project.Status[types.ProjectStatusOutputs] = false
	}
	if err := fs.updateProject(t, workspaceId, project); err != nil {
		return fmt.Errorf("failed to update project id: %s . Error: %q", projectId, err)
	}
	// effects
	projOutputPath := filepath.Join(common.Config.DataDir, PROJECTS_DIR, projectId, PROJECT_OUTPUTS_DIR, projOutputId)
	if err := os.RemoveAll(projOutputPath); err != nil {
		return fmt.Errorf("failed to remove the project output with id: %s directory at path %s . Error: %q", projOutputId, projOutputPath, err)
	}
	return nil
}

// GetQuestion returns the current question for application which is in transformation phase.
// If there are no more questions, this will return "", nil.
func (fs *FileSystem) GetQuestion(workspaceId, projectId, projOutputId string) (problem string, err error) {
	db, err := fs.GetDatabase(true)
	if err != nil {
		return problem, err
	}
	defer db.Close()
	err = db.View(func(t *bolt.Tx) error {
		problem, err = fs.getQuestion(t, workspaceId, projectId, projOutputId)
		return err
	})
	return problem, err
}

func (fs *FileSystem) getQuestion(t *bolt.Tx, workspaceId, projectId, projOutputId string) (problem string, err error) {
	project, err := fs.readProject(t, workspaceId, projectId)
	if err != nil {
		return "", err
	}
	projOutput, ok := project.Outputs[projOutputId]
	if !ok {
		return "", types.ErrorDoesNotExist{Id: projOutputId}
	}
	if projOutput.Status == types.ProjectOutputStatusDoneSuccess {
		logrus.Debugf("the transformation for output %s of project %s already finished", projOutputId, projectId)
		return "", nil
	}
	if projOutput.Status != types.ProjectOutputStatusInProgress {
		return "", fmt.Errorf("expected the project output to be in status '%s' . Actual: %+v", types.ProjectOutputStatusInProgress, projOutput)
	}
	qaServerBucket := t.Bucket([]byte(M2K_QA_SERVER_METADATA_FILE))
	if qaServerBucket == nil {
		return "", fmt.Errorf("the qa server bucket is missing")
	}
	qaServerMetaBytes := qaServerBucket.Get([]byte(projOutputId))
	if qaServerMetaBytes == nil {
		return "", fmt.Errorf("the output %s of project %s is missing from the qa server bucket", projOutputId, projectId)
	}
	qaServerMetadata := types.QAServerMetadata{}
	if err := json.Unmarshal(qaServerMetaBytes, &qaServerMetadata); err != nil {
		return "", fmt.Errorf("failed to unmarshal the qa server metadata as json. Actual: %s\nError: %q", string(qaServerMetaBytes), err)
	}
	quesURL := fmt.Sprintf("http://%s:%d/problems/current", qaServerMetadata.Host, qaServerMetadata.Port)
	logrus.Debugf("Getting the next question from the QA server at URL %s", quesURL)
	resp, err := http.Get(quesURL)
	checkErr(err)
	if err != nil {
		return "", fmt.Errorf("failed to send a GET request to the URL %s . Error: %q", quesURL, err)
	}
	if resp.StatusCode < 200 || resp.StatusCode > 299 {
		return "", fmt.Errorf("got an error response status code. Status: %s", resp.Status)
	}
	defer resp.Body.Close()
	respBodyBytes, err := io.ReadAll(resp.Body)
	if err != nil {
		return "", fmt.Errorf("failed to read the response body. Error: %q", err)
	}
	question := string(respBodyBytes)
	if question == "" {
		logrus.Debugf("there are no more questions to get.")
		return "", nil
	}
	logrus.Debugf("got a new question: %s", question)
	return question, nil
}

// PostSolution posts the solution for the current question
func (fs *FileSystem) PostSolution(workspaceId, projectId, projOutputId, solution string) error {
	db, err := fs.GetDatabase(true)
	if err != nil {
		return err
	}
	defer db.Close()
	return db.View(func(t *bolt.Tx) error {
		return fs.postSolution(t, workspaceId, projectId, projOutputId, solution)
	})
}

func (fs *FileSystem) postSolution(t *bolt.Tx, workspaceId, projectId, projOutputId, solution string) error {
	project, err := fs.readProject(t, workspaceId, projectId)
	if err != nil {
		return err
	}
	projOutput, ok := project.Outputs[projOutputId]
	if !ok {
		return types.ErrorDoesNotExist{Id: projOutputId}
	}
	if projOutput.Status == types.ProjectOutputStatusDoneSuccess {
		logrus.Debugf("the transformation for output %s of project %s already finished", projOutputId, projectId)
		return nil
	}
	if projOutput.Status != types.ProjectOutputStatusInProgress {
		return fmt.Errorf("expected the project output to be in status '%s' . Actual: %+v", types.ProjectOutputStatusInProgress, projOutput)
	}
	qaServerBucket := t.Bucket([]byte(M2K_QA_SERVER_METADATA_FILE))
	if qaServerBucket == nil {
		return fmt.Errorf("the qa server bucket is missing")
	}
	qaServerMetaBytes := qaServerBucket.Get([]byte(projOutputId))
	if qaServerMetaBytes == nil {
		return fmt.Errorf("the output %s of project %s is missing from the qa server bucket", projOutputId, projectId)
	}
	qaServerMetadata := types.QAServerMetadata{}
	if err := json.Unmarshal(qaServerMetaBytes, &qaServerMetadata); err != nil {
		return fmt.Errorf("failed to unmarshal the qa server metadata as json. Actual: %s\nError: %q", string(qaServerMetaBytes), err)
	}
	quesURL := fmt.Sprintf("http://%s:%d/problems/current/solution", qaServerMetadata.Host, qaServerMetadata.Port)
	logrus.Debugf("Posting the solution to the URL %s", quesURL)
	resp, err := http.Post(quesURL, common.CONTENT_TYPE_JSON, bytes.NewBufferString(solution))
	if err != nil {
		return fmt.Errorf("failed to send the POST request to the URL %s . Error: %q", quesURL, err)
	}
	if resp.StatusCode < 200 || resp.StatusCode > 299 {
		if resp.StatusCode == 406 {
			respBodyBytes, err := io.ReadAll(resp.Body)
			if err != nil {
				return types.ErrorValidation{Reason: "not a valid answer to the question"}
			}
			return types.ErrorValidation{Reason: string(respBodyBytes)}
		}
		return fmt.Errorf("got an error response status code. Status: %s", resp.Status)
	}
	defer resp.Body.Close()
	respBodyBytes, err := io.ReadAll(resp.Body)
	if err != nil {
		return fmt.Errorf("failed to read the response body. Error: %q", err)
	}
	logrus.Debugf("got the response %s", string(respBodyBytes))
	return nil
}

// NewFileSystem returns a new IFileSystem object which manages workspaces and projects in the filesystem
func NewFileSystem() (*FileSystem, error) {
	logrus.Trace("NewFileSystem start")
	defer logrus.Trace("NewFileSystem end")
	fileSystem := new(FileSystem)
	if common.Config.CleanStartup {
		logrus.Infof("deleting the data directory if it already exists at path '%s'", common.Config.DataDir)
		if err := os.RemoveAll(common.Config.DataDir); err != nil {
			return fileSystem, fmt.Errorf("failed to remove the data directory at path '%s' . Error: %w", common.Config.DataDir, err)
		}
	}
	logrus.Infof("creating the data directory at path '%s'", common.Config.DataDir)
	if err := os.MkdirAll(common.Config.DataDir, DEFAULT_DIRECTORY_PERMISSIONS); err != nil {
		return fileSystem, fmt.Errorf("failed to make the data directory at path '%s' . Error: %w", common.Config.DataDir, err)
	}
	workDir := filepath.Join(common.Config.DataDir, WORKSPACES_DIR)
	logrus.Debugf("making the workspaces directory at %s", workDir)
	if err := os.MkdirAll(workDir, DEFAULT_DIRECTORY_PERMISSIONS); err != nil {
		logrus.Fatalf("failed to make the workspaces directory at path %s . Error: %q", workDir, err)
	}
	projDir := filepath.Join(common.Config.DataDir, PROJECTS_DIR)
	logrus.Debugf("making the projects directory at %s", projDir)
	if err := os.MkdirAll(projDir, DEFAULT_DIRECTORY_PERMISSIONS); err != nil {
		logrus.Fatalf("failed to make the projects directory at path %s . Error: %q", projDir, err)
	}
	db, err := fileSystem.GetDatabase(false)
	if err != nil {
		logrus.Fatalf("failed to create/get the database in read/write mode while setting up handlers. Error: %q", err)
	}
	err = db.Update(func(t *bolt.Tx) error {
		if _, err := t.CreateBucketIfNotExists([]byte(WORKSPACES_BUCKET)); err != nil {
			return err
		}
		if _, err := t.CreateBucketIfNotExists([]byte(PROJECTS_BUCKET)); err != nil {
			return err
		}
		if _, err := t.CreateBucketIfNotExists([]byte(M2K_PLAN_PROGRESS_SERVER_METADATA_FILE)); err != nil {
			return err
		}
		if _, err := t.CreateBucketIfNotExists([]byte(M2K_QA_SERVER_METADATA_FILE)); err != nil {
			return err
		}
		return nil
	})
	db.Close()
	if err != nil {
		logrus.Fatalf("failed to create the buckets in the database. Error: %q", err)
	}
	workspaces, err := fileSystem.ListWorkspaces(nil)
	if err != nil {
		return fileSystem, fmt.Errorf("failed to list the workspaces. Error: %w", err)
	}
	for _, workspace := range workspaces {
		projects, err := fileSystem.ListProjects(workspace.Id)
		if err != nil {
			return fileSystem, fmt.Errorf("failed to list the projects in the workspace with id '%s' . Error: %w", workspace.Id, err)
		}
		for _, project := range projects {
			for _, projOutput := range project.Outputs {
				if err := fileSystem.ResumeTransformation(workspace.Id, project.Id, projOutput.Id, false); err != nil {
					logrus.Debugf("failed to resume the transformation for output with id: %s of project id: %s . Error: %q", projOutput.Id, project.Id, err)
				}
			}
		}
	}
	return fileSystem, nil
}

// Utility functions
func isVerbose() bool {
	return common.Config.LogLevel == logrus.TraceLevel.String() || common.Config.LogLevel == logrus.DebugLevel.String()
}

func validateAndProcessPlan(plan string, shouldProcess bool) (string, error) {
	// TODO: better validation of the plan
	p := map[string]interface{}{}
	if err := yaml.Unmarshal([]byte(plan), &p); err != nil {
		return "", fmt.Errorf("failed to unmarshal the plan as yaml. Error: %q", err)
	}
	if pApiVerI, ok := p["apiVersion"]; !ok {
		return "", fmt.Errorf("'apiVersion' is missing from the plan")
	} else if pApiVer, ok := pApiVerI.(string); !ok {
		return "", fmt.Errorf("'apiVersion' is not a string. Actual value is %+v of type %T", pApiVerI, pApiVerI)
	} else if !common.IsStringPresent(common.KNOWN_API_VERSIONS, pApiVer) {
		return "", fmt.Errorf("'apiVersion' is invalid. Expected one of %+v . Actual: %s", common.KNOWN_API_VERSIONS, pApiVer)
	} else if pKindI, ok := p["kind"]; !ok {
		return "", fmt.Errorf("'kind' is missing from the plan")
	} else if pKind, ok := pKindI.(string); !ok {
		return "", fmt.Errorf("'kind' is not a string. Actual value is %+v of type %T", pKindI, pKindI)
	} else if pKind != "Plan" {
		return "", fmt.Errorf("'kind' is invalid. Expected 'Plan' . Actual: %s", pKind)
	} else if pMetaI, ok := p["metadata"]; !ok {
		return "", fmt.Errorf("'metadata' is missing from the plan")
	} else if pMeta, ok := pMetaI.(map[string]interface{}); !ok {
		return "", fmt.Errorf("'metadata' is not a map[string]interface{} . Actual value is %+v of type %T", pMetaI, pMetaI)
	} else if pMetaNameI, ok := pMeta["name"]; !ok {
		return "", fmt.Errorf("'metadata.name' is missing from the plan")
	} else if pMetaName, ok := pMetaNameI.(string); !ok {
		return "", fmt.Errorf("'metadata.name' is not a string. Actual value is %+v of type %T", pMetaNameI, pMetaNameI)
	} else if _, err := common.NormalizeName(pMetaName); err != nil {
		return "", fmt.Errorf("'metadata.name' is invalid. failed to normalize the name. Error: %q", err)
	} else if pSpecI, ok := p["spec"]; !ok {
		return "", fmt.Errorf("'spec' is missing from the plan")
	} else if pSpec, ok := pSpecI.(map[string]interface{}); !ok {
		return "", fmt.Errorf("'spec' is not a map[string]interface{} . Actual value is %+v of type %T", pSpecI, pSpecI)
	} else if pSpecSourceDirI, ok := pSpec["sourceDir"]; !ok {
		return "", fmt.Errorf("'spec.sourceDir' is missing from the plan")
	} else if pSpecSourceDir, ok := pSpecSourceDirI.(string); !ok {
		return "", fmt.Errorf("'spec.sourceDir' is not a string. Actual value is %+v of type %T", pSpecSourceDirI, pSpecSourceDirI)
	} else if pSpecSourceDir != SOURCES_DIR && pSpecSourceDir != "" {
		return "", fmt.Errorf("'spec.sourceDir' is invalid. Expected 'source' . Actual: %s", pSpecSourceDir)
	} else {
		// TODO: better processing of the plan
		pMeta["name"], _ = common.NormalizeName(pMetaName)
	}
	return plan, nil
}

// TODO
func (fs *FileSystem) runPlan(currentRunDir string, currentRunConfigPaths []string, currentRunSrcDir, currentRunCustDir, currentRunOutDir, message string, port int, workspaceId, projectId, projectName string, debugMode bool) error {
	logrus.Infof("Starting plan at directory %s using configs %+v and source %s and customizations %s to output %s", currentRunDir, currentRunConfigPaths, currentRunSrcDir, currentRunCustDir, currentRunOutDir)
	normName, err := common.NormalizeName(projectName)
	if err != nil {
		return types.ErrorValidation{Reason: fmt.Sprintf("failed to normalize the project name %s . Error: %q", projectName, err)}
	}
	cmdArgs := []string{"plan", "--name", normName, "--plan-progress-port", cast.ToString(port), "--log-file", M2K_CLI_LOG_FILE}
	verbose := debugMode || isVerbose()
	if currentRunSrcDir != "" {
		cmdArgs = append(cmdArgs, "--source", currentRunSrcDir)
	}
	if verbose {
		cmdArgs = append(cmdArgs, "--log-level", "trace")
	}
	if !common.Config.EnableLocalExecution {
		cmdArgs = append(cmdArgs, "--disable-local-execution")
	}
	for _, p := range currentRunConfigPaths {
		cmdArgs = append(cmdArgs, "--config", p)
	}
	if currentRunCustDir != "" {
		cmdArgs = append(cmdArgs, "--customizations", currentRunCustDir)
	}
	logrus.Infof("plan cmdArgs: %+v", cmdArgs)
	ctx := context.Background()
	if common.Config.PlanTimeoutSeconds > 0 {
		var cancel context.CancelFunc
		ctx, cancel = context.WithTimeout(ctx, time.Duration(common.Config.PlanTimeoutSeconds)*time.Second)
		defer cancel()
	}
	cmd := exec.CommandContext(ctx, common.APP_NAME, cmdArgs...)
	cmd.Dir = currentRunDir
	stdout, err := cmd.StdoutPipe()
	if err != nil {
		logrus.Errorf("failed to get the stdout pipe for the plan command. Error: %q", err)
		return err
	}
	stderr, err := cmd.StderrPipe()
	if err != nil {
		logrus.Errorf("failed to get the stderr pipe for the plan command. Error: %q", err)
		return err
	}
	if err := cmd.Start(); err != nil {
		logrus.Errorf("failed to start the plan command. Error: %q", err)
		return err
	}
	outCh := make(chan string, 10)
	stdoutReader := bufio.NewReader(stdout)
	var wg sync.WaitGroup
	wg.Add(1)
	go func() {
		text, err := stdoutReader.ReadString('\n')
		for err == nil {
			updatedText := strings.TrimSpace(TIMESTAMP_REGEXP.ReplaceAllLiteralString(text, message))
			if updatedText != "" {
				outCh <- updatedText
			}
			text, err = stdoutReader.ReadString('\n')
		}
		logrus.Debugf("failed to fetch the stdout of move2kube plan. Error: %q", err)
		wg.Done()
	}()
	stderrReader := bufio.NewReader(stderr)
	wg.Add(1)
	go func() {
		text, err := stderrReader.ReadString('\n')
		for err == nil {
			updatedText := strings.TrimSpace(TIMESTAMP_REGEXP.ReplaceAllLiteralString(text, message))
			if updatedText != "" {
				outCh <- updatedText
			}
			text, err = stderrReader.ReadString('\n')
		}
		logrus.Debugf("failed to fetch the stderr of move2kube plan. Error: %q", err)
		wg.Done()
	}()
	go func() {
		wg.Wait()
		close(outCh)
	}()
	for outputLine := range outCh {
		if verbose {
			generateVerboseLogs(outputLine)
		} else {
			logrus.Info(outputLine)
		}
	}
	isCtxClosed := false
	select {
	case <-ctx.Done():
		logrus.Debug("ctx closed")
		isCtxClosed = true
	default:
		logrus.Debug("ctx not closed")
	}
	// release lock
	db, err := fs.GetDatabase(false)
	if err != nil {
		err = fmt.Errorf("failed to get the database in read/write mode. Error: %q", err)
		logrus.Error(err)
		return err
	}
	defer db.Close()
	err = db.Update(func(t *bolt.Tx) error {
		logrus.Trace("planning finished. Update start")
		defer logrus.Trace("planning finished. Update end")
		// checks
		logrus.Debug("planning finished. inside Update. just before checks start")
		project, err := fs.readProject(t, workspaceId, projectId)
		if err != nil {
			logrus.Errorf("inside runPlan, failed to read the project after planning completed. Error: %q", err)
			return err
		}
		// update state
		logrus.Debug("planning finished. inside Update. just before update start")
		project.Status[types.ProjectStatusPlanning] = false
		project.Status[types.ProjectStatusPlan] = true
		project.Status[types.ProjectStatusStalePlan] = false
		project.Status[types.ProjectStatusPlanError] = false
		if isCtxClosed {
			logrus.Debug("planning finished. inside Update. inside isCtxClosed if block")
			// planning was interrupted for some reason
			project.Status[types.ProjectStatusPlan] = false
			project.Status[types.ProjectStatusPlanError] = true
			if err := ctx.Err(); err == context.Canceled {
				logrus.Errorf("planning for project %s was cancelled. Error: %q", projectId, err)
			} else if err == context.DeadlineExceeded {
				logrus.Errorf("planning for project %s exceeded the timeout. Error: %q", projectId, err)
			} else {
				logrus.Errorf("planning for project %s stopped because the context was closed. Error: %q", projectId, err)
			}
		}
		if err := fs.updateProject(t, workspaceId, project); err != nil {
			return fmt.Errorf("failed to update the project to unlock the plan generation. Error: %q", err)
		}
		// effects
		logrus.Debug("planning finished. inside Update. just before effects start")
		projInputsDir := filepath.Join(common.Config.DataDir, PROJECTS_DIR, projectId, INPUTS_DIR, EXPANDED_DIR)
		dstPlanPath := filepath.Join(projInputsDir, M2K_PLAN_FILENAME)
		srcPlanPath := filepath.Join(currentRunOutDir, M2K_PLAN_FILENAME)
		if err := os.MkdirAll(projInputsDir, DEFAULT_DIRECTORY_PERMISSIONS); err != nil {
			return fmt.Errorf("failed to create the project inputs expanded directory at path %s to copy the plan to. Error: %q", projInputsDir, err)
		}
		if err := CopyFile(dstPlanPath, srcPlanPath); err != nil {
			return fmt.Errorf("failed to copy the plan file from %s to %s after planning finished. Error: %q", srcPlanPath, dstPlanPath, err)
		}
		return nil
	})
	if err != nil {
		logrus.Errorf("failed to update the database after planning finished. Error: %q", err)
	}
	return err
}

func (fs *FileSystem) runTransform(currentRunDir string, currentRunConfigPaths []string, currentRunSrcDir, currentRunCustDir, currentRunOutDir, message string, port int, transformCh chan error, workspaceId, projectId string, projOutput types.ProjectOutput, debugMode bool, overwriteOutDir bool) error {
	logrus.Infof("Starting transformation in %s with configs from %+v and source from %s , customizations from %s and output to %s", currentRunDir, currentRunConfigPaths, currentRunSrcDir, currentRunCustDir, currentRunOutDir)
	portStr, err := cast.ToStringE(port)
	if err != nil {
		return fmt.Errorf("failed to convert the port '%d' to a string. Error: %q", port, err)
	}
	cmdArgs := []string{"transform", "--qa-disable-cli", "--qa-port", portStr, "--output", currentRunOutDir, "--log-file", M2K_CLI_LOG_FILE}
	if currentRunSrcDir != "" {
		cmdArgs = append(cmdArgs, "--source", currentRunSrcDir)
	}
	if overwriteOutDir {
		cmdArgs = append(cmdArgs, "--overwrite")
	}
	verbose := debugMode || isVerbose()
	if verbose {
		cmdArgs = append(cmdArgs, "--log-level", "trace")
	}
	if !common.Config.EnableLocalExecution {
		cmdArgs = append(cmdArgs, "--disable-local-execution")
	}
	if currentRunCustDir != "" {
		cmdArgs = append(cmdArgs, "--customizations", currentRunCustDir)
	}
	for _, p := range currentRunConfigPaths {
		cmdArgs = append(cmdArgs, "--config", p)
	}
	logrus.Infof("transform cmdArgs: %+v", cmdArgs)
	ctx := context.Background()
	if common.Config.TransformTimeoutSeconds > 0 {
		var cancel context.CancelFunc
		ctx, cancel = context.WithTimeout(ctx, time.Duration(common.Config.TransformTimeoutSeconds)*time.Second)
		defer cancel()
	}
	cmd := exec.CommandContext(ctx, common.APP_NAME, cmdArgs...)
	cmd.Dir = currentRunDir
	stdout, err := cmd.StdoutPipe()
	if err != nil {
		logrus.Errorf("failed to get the stdout pipe for the transform command. Error: %q", err)
		return err
	}
	stderr, err := cmd.StderrPipe()
	if err != nil {
		logrus.Errorf("failed to get the stderr pipe for the transform command. Error: %q", err)
		return err
	}
	if err := cmd.Start(); err != nil {
		logrus.Errorf("failed to start the transform command. Error: %q", err)
		return err
	}
	wg := sync.WaitGroup{}
	outCh := make(chan string, 10)
	stdoutReader := bufio.NewReader(stdout)
	wg.Add(1)
	go func() {
		text, err := stdoutReader.ReadString('\n')
		for err == nil {
			updatedText := strings.TrimSpace(TIMESTAMP_REGEXP.ReplaceAllLiteralString(text, message))
			if updatedText != "" {
				outCh <- updatedText
			}
			text, err = stdoutReader.ReadString('\n')
		}
		logrus.Debugf("failed to fetch the stdout of move2kube transform. Error: %q", err)
		wg.Done()
	}()
	stderrReader := bufio.NewReader(stderr)
	wg.Add(1)
	go func() {
		text, err := stderrReader.ReadString('\n')
		for err == nil {
			updatedText := strings.TrimSpace(TIMESTAMP_REGEXP.ReplaceAllLiteralString(text, message))
			if updatedText != "" {
				outCh <- updatedText
			}
			text, err = stderrReader.ReadString('\n')
		}
		logrus.Debugf("failed to fetch the stderr of move2kube transform. Error: %q", err)
		wg.Done()
	}()
	go func() {
		wg.Wait()
		close(outCh)
	}()
	flag := true
	for outputLine := range outCh {
		if flag && strings.Contains(outputLine, portStr) {
			flag = false
			transformCh <- nil
			close(transformCh)
		}
		if verbose {
			generateVerboseLogs(outputLine)
		} else {
			logrus.Info(outputLine)
		}
	}
	isCtxClosed := false
	select {
	case <-ctx.Done():
		logrus.Debug("ctx closed")
		isCtxClosed = true
	default:
		logrus.Debug("ctx not closed")
	}
	// create the output zip file
	if err := copyOverPlanConfigAndQACache(currentRunDir, currentRunOutDir); err != nil {
		logrus.Errorf("failed to copy over the m2kconfig.yaml and m2kqacache.yaml. Error: %q", err)
	}
	zipPath := filepath.Join(currentRunDir, "output.zip")
	if err := archiver.NewZip().Archive([]string{currentRunOutDir}, zipPath); err != nil {
		return fmt.Errorf("failed to create the output zip file at path %s using the output directory at path %s . Error: %q", zipPath, currentRunOutDir, err)
	}
	// indicate that the transformation is done
	db, err := fs.GetDatabase(false)
	if err != nil {
		return fmt.Errorf("failed to get a database in read/write mode. Error: %q", err)
	}
	defer db.Close()
	err = db.Update(func(t *bolt.Tx) error {
		project, err := fs.readProject(t, workspaceId, projectId)
		if err != nil {
			return fmt.Errorf("failed to read the project with id %s to update the status of the output %+v . Error: %q", projectId, projOutput, err)
		}
		po := project.Outputs[projOutput.Id]
		po.Status = types.ProjectOutputStatusDoneSuccess
		if isCtxClosed {
			// transformation was interrupted for some reason
			po.Status = types.ProjectOutputStatusDoneError
			if err := ctx.Err(); err == context.Canceled {
				logrus.Errorf("transformation for output %s of project %s was cancelled. Error: %q", projOutput.Id, projectId, err)
			} else if err == context.DeadlineExceeded {
				logrus.Errorf("transformation for output %s of project %s exceeded the timeout. Error: %q", projOutput.Id, projectId, err)
			} else {
				logrus.Errorf("transformation for output %s of project %s stopped because the context was closed. Error: %q", projOutput.Id, projectId, err)
			}
		}
		project.Outputs[projOutput.Id] = po
		if err := fs.updateProject(t, workspaceId, project); err != nil {
			return fmt.Errorf("failed to update the project to finish the transformation. Error: %q", err)
		}
		if common.Config.CleanUpAfterTransform {
			if err := cleanUpAfterTransform(currentRunDir); err != nil {
				return fmt.Errorf("failed to clean up after transformation finished. Error: %q", err)
			}
		}
		return nil
	})
	if err != nil {
		logrus.Errorf("failed to update the database after transformation finished. Error: %q", err)
	}
	return err
}

func cleanUpAfterTransform(currentRunDir string) error {
	sourcesPath := filepath.Join(currentRunDir, SOURCES_DIR)
	if err := os.RemoveAll(sourcesPath); err != nil {
		return fmt.Errorf("failed to clean up the sources directory at path %s . Error: %q", sourcesPath, err)
	}
	custsPath := filepath.Join(currentRunDir, CUSTOMIZATIONS_DIR)
	if err := os.RemoveAll(custsPath); err != nil {
		return fmt.Errorf("failed to clean up the customizations directory at path %s . Error: %q", custsPath, err)
	}
	configsPath := filepath.Join(currentRunDir, CONFIGS_DIR)
	if err := os.RemoveAll(configsPath); err != nil {
		return fmt.Errorf("failed to clean up the configs directory at path %s . Error: %q", configsPath, err)
	}
	return nil
}

func copyOverPlanConfigAndQACache(srcDir, destDir string) error {
	planSrcPath := filepath.Join(srcDir, "m2k.plan")
	configSrcPath := filepath.Join(srcDir, "m2kconfig.yaml")
	graphSrcPath := filepath.Join(srcDir, "m2k-graph.json")
	qaCacheSrcPath := filepath.Join(srcDir, "m2kqacache.yaml")
	planDestPath := filepath.Join(destDir, "m2k.plan")
	configDestPath := filepath.Join(destDir, "m2kconfig.yaml")
	graphDestPath := filepath.Join(destDir, "m2k-graph.json")
	qaCacheDestPath := filepath.Join(destDir, "m2kqacache.yaml")
	planBytes, err := os.ReadFile(planSrcPath)
	if err != nil {
		return fmt.Errorf("failed to read the plan file at path %s . Error: %q", planSrcPath, err)
	}
	if err := os.WriteFile(planDestPath, planBytes, DEFAULT_FILE_PERMISSIONS); err != nil {
		return fmt.Errorf("failed to write the plan file to the path %s . Error: %q", planDestPath, err)
	}
	configBytes, err := os.ReadFile(configSrcPath)
	if err != nil {
		return fmt.Errorf("failed to read the config file at path %s . Error: %q", configSrcPath, err)
	}
	if err := os.WriteFile(configDestPath, configBytes, DEFAULT_FILE_PERMISSIONS); err != nil {
		return fmt.Errorf("failed to write the config file to the path %s . Error: %q", configDestPath, err)
	}
	graphBytes, err := os.ReadFile(graphSrcPath)
	if err != nil {
		return fmt.Errorf("failed to read the m2k graph file at path %s . Error: %q", graphSrcPath, err)
	}
	if err := os.WriteFile(graphDestPath, graphBytes, DEFAULT_FILE_PERMISSIONS); err != nil {
		return fmt.Errorf("failed to write the m2k graph file to the path %s . Error: %q", graphDestPath, err)
	}
	qaCacheBytes, err := os.ReadFile(qaCacheSrcPath)
	if err != nil {
		return fmt.Errorf("failed to read the qa cache file at path %s . Error: %q", qaCacheSrcPath, err)
	}
	if err := os.WriteFile(qaCacheDestPath, qaCacheBytes, DEFAULT_FILE_PERMISSIONS); err != nil {
		return fmt.Errorf("failed to write the qa cache file to the path %s . Error: %q", qaCacheDestPath, err)
	}
	return nil
}

// generateVerboseLogs synchronizes move2kube-api loggging level wrt move2kube logging level
func generateVerboseLogs(message string) {
	var loggingLevel string
	sm := LOG_LEVEL_REGEXP.FindStringSubmatch(message)
	if len(sm) > 1 {
		loggingLevel = sm[1]
	} else {
		loggingLevel = "info"
	}
	syncLoggingLevel(loggingLevel, message)
}

// syncLoggingLevel matches log levels of Move2Kube-api and Move2Kube
func syncLoggingLevel(loggingLevel, message string) {
	switch {
	case loggingLevel == "trace":
		logrus.Trace(message)
	case loggingLevel == "debug":
		logrus.Debug(message)
	case loggingLevel == "info":
		logrus.Info(message)
	case loggingLevel == "warning":
		logrus.Warn(message)
	case loggingLevel == "error":
		logrus.Error(message)
	case loggingLevel == "fatal":
		logrus.Error(message)
	case loggingLevel == "panic":
		logrus.Error(message)
	default:
		logrus.Info(message)
	}
}

// putM2KIgnore writes a .m2kignore file to a directory that ignores the contents of that directory.
// NOTE: It will not ignore subdirectories. if the directory does not exist it will be created.
func putM2KIgnore(path string) error {
	if err := os.MkdirAll(path, DEFAULT_DIRECTORY_PERMISSIONS); err != nil {
		return fmt.Errorf("failed to create a directory at the path %s . Error: %q", path, err)
	}
	m2kIgnorePath := filepath.Join(path, ".m2kignore")
	if err := os.WriteFile(m2kIgnorePath, []byte("."), DEFAULT_FILE_PERMISSIONS); err != nil {
		return fmt.Errorf("failed to write a .m2kingore file to the path %s . Error: %q", m2kIgnorePath, err)
	}
	return nil
}

// CopyFile copies a file from src to dst.
// The dst file will be truncated if it exists.
// Returns an error if it failed to copy all the bytes.
func CopyFile(dst, src string) error {
	logrus.Tracef("CopyFile start. src %s dst %s", src, dst)
	defer logrus.Trace("CopyFile end")
	srcfile, err := os.Open(src)
	if err != nil {
		return fmt.Errorf("failed to open the source file at path %q Error: %q", src, err)
	}
	defer srcfile.Close()
	srcfileinfo, err := srcfile.Stat()
	if err != nil {
		return fmt.Errorf("failed to get size of the source file at path %q Error: %q", src, err)
	}
	srcfilesize := srcfileinfo.Size()
	dstfile, err := os.OpenFile(dst, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, DEFAULT_FILE_PERMISSIONS)
	if err != nil {
		return fmt.Errorf("failed to create the destination file at path %q Error: %q", dst, err)
	}
	defer dstfile.Close()
	written, err := io.Copy(dstfile, srcfile)
	if written != srcfilesize {
		return fmt.Errorf("failed to copy all the bytes from source %q to destination %q. %d out of %d bytes written. Error: %v", src, dst, written, srcfilesize, err)
	}
	if err != nil {
		return fmt.Errorf("failed to copy from source %q to destination %q. Error: %q", src, dst, err)
	}
	return dstfile.Close()
}

func copyDir(src, dest string) error {
	logrus.Tracef("copyDir start. src: %s dest: %s", src, dest)
	defer logrus.Trace("copyDir end")
	cmd := exec.Command("cp", "-r", src, dest)
	return cmd.Run()
}

func checkErr(err error) {
	logrus.Trace("checkErr start")
	if err == nil {
		logrus.Debug("Ok")
		return
	} else if netError, ok := err.(net.Error); ok {
		logrus.Debugf("net.Error: %q", netError)
		if netError.Timeout() {
			logrus.Debug("Timeout")
			return
		}
	}
	switch t := err.(type) {
	case *net.OpError:
		if t.Op == "dial" {
			logrus.Debug("Unknown host")
		} else if t.Op == "read" {
			logrus.Debug("Connection refused")
		} else {
			logrus.Debugf("*net.OpError t.Op %+v", t.Op)
		}
	case syscall.Errno:
		if t == syscall.ECONNREFUSED {
			logrus.Debug("Connection refused")
		} else {
			logrus.Debugf("syscall.Errno t %+v", t)
		}
	default:
		logrus.Debugf("default %T %+v", t, t)
	}
	logrus.Trace("checkErr end")
}

func getConfigPaths(configsDir string, project types.Project) ([]string, error) {
	configPaths := []string{}
	times := []int64{}
	for _, inp := range project.Inputs {
		if inp.Type != types.ProjectInputConfigs {
			continue
		}
		t, err := time.Parse(time.RFC3339, inp.Timestamp)
		if err != nil {
			continue
		}
		times = append(times, t.Unix())
		configPaths = append(configPaths, filepath.Join(configsDir, inp.NormalizedName))
	}
	sort.Sort(mySortable{ids: configPaths, times: times})
	return configPaths, nil
}

// mySortable implements the sort.Interface
type mySortable struct {
	ids   []string
	times []int64
}

func (s mySortable) Len() int {
	return len(s.ids)
}

func (s mySortable) Less(i, j int) bool {
	return s.times[i] < s.times[j]
}

func (s mySortable) Swap(i, j int) {
	s.times[i], s.times[j] = s.times[j], s.times[i]
	s.ids[i], s.ids[j] = s.ids[j], s.ids[i]
}
